#!/usr/bin/python
# This Python file uses the following encoding: utf-8

# Recipe Robot
# Copyright 2015 Elliot Jordan, Shea G. Craig
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""
recipe-robot

Easily and automatically create AutoPkg recipes.

usage: recipe-robot [-h] [-v] [-o OUTPUT_DIR] [-t RECIPE_TYPES]
                    [--include-existing] [--keep-cache] [--config]
                    input_path

positional arguments:
  input_path            Path from which to derive AutoPkg recipes. This can be
                        one of the following: existing app, existing AutoPkg
                        recipe, Sparkle feed, GitHub or SourceForge URL, or
                        direct download URL.

optional arguments:
  -h, --help            show this help message and exit
  -v, --verbose         Generate additional output about the process.
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        Path to a folder you'd like to save your generated
                        recipes in.
  -t RECIPE_TYPES, --recipe-types RECIPE_TYPES
                        The types of recipe you'd like to generate.
  --include-existing    Offer to generate recipes even if one already exists
                        on GitHub.
  --keep-cache          Keep the Recipe Robot cache, instead of performing the
                        usual cleanup. This allows you to manually inspect the
                        files Recipe Robot downloaded. The cache will be
                        cleared again upon next run.
  --config              Adjust Recipe Robot preferences prior to generating
                        recipes.
"""


import argparse
from distutils.version import StrictVersion, LooseVersion
import json
import os
#TODO: Remove for release
import pdb
import pprint
import random
import re
import shutil
import sys
from urllib2 import urlopen, build_opener, URLError, HTTPError
from urlparse import urlparse
from xml.etree.ElementTree import parse, ParseError

import recipe_robot_lib
from recipe_robot_lib.tools import (create_dest_dirs,
                                    get_exitcode_stdout_stderr, robo_print,
                                    LogLevel, OutputMode, print_welcome_text,
                                    __version__)
# TODO(Elliot): Can we use the one at /Library/AutoPkg/FoundationPlist instead?
# Or not use it at all (i.e. use the preferences system correctly). (#16)
try:
    from recipe_robot_lib import FoundationPlist
except:
    print '[WARNING] importing plistlib as FoundationPlist'
    import plistlib as FoundationPlist


# Global variables.
prefs_file = os.path.expanduser(
    "~/Library/Preferences/com.elliotjordan.recipe-robot.plist")
cache_dir = os.path.expanduser("~/Library/Caches/Recipe Robot")

# Build the list of download formats we know about.
supported_image_formats = ("dmg", "iso")  # downloading iso unlikely
supported_archive_formats = ("zip", "tar.gz", "gzip", "tar.bz2", "tbz", "tgz")
supported_install_formats = ("pkg", "mpkg")  # downloading mpkg unlikely
all_supported_formats = (supported_image_formats + supported_archive_formats +
                         supported_install_formats)


def build_argument_parser():
    """Build and return the argument parser for Recipe Robot.

    Returns:
        Parser object.
    """

    parser = argparse.ArgumentParser(
        description="Easily and automatically create AutoPkg recipes.")
    parser.add_argument(
        "input_path",
        nargs='?',
        help="Path from which to derive AutoPkg recipes. This can be one of "
             "the following: existing app, existing AutoPkg recipe, Sparkle "
             "feed, GitHub or SourceForge URL, or direct download URL.")
    parser.add_argument(
        "--config",
        action="store_true",
        help="Adjust Recipe Robot preferences prior to generating recipes.")
    parser.add_argument(
        "--include-existing",
        action="store_true",
        help="Offer to generate recipes even if one already exists on GitHub.")
    parser.add_argument(
        "--keep-cache",
        action="store_true",
        help="Keep the Recipe Robot cache, instead of performing the usual "
             "cleanup. This allows you to manually inspect the files Recipe "
             "Robot downloaded. The cache will be cleared again upon next "
             "run.")
    parser.add_argument(
        "--github-token",
        action="store_true",
        help="Use a GitHub API token when searching for existing recipes.")
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Generate additional output about the process.")
    return parser


def init_recipes():
    """Store information related to each supported AutoPkg recipe type.

    Returns:
        A tuple of dicts that describe all the AutoPkg recipe types we know about.
    """

    recipes = ({
        "type": "download",
        "description": "Downloads an app in whatever format the developer "
                       "provides."
        }, {
            "type": "munki",
            "description": "Imports into your Munki repository."
        }, {
            "type": "pkg",
            "description": "Creates a standard pkg installer file."
        }, {
            "type": "install",
            "description": "Installs the app on the computer running AutoPkg."
        }, {
            "type": "jss",
            "description": "Imports into your Casper JSS and creates "
                           "necessary groups, policies, etc."
        }, {
            "type": "absolute",
            "description": "Imports into your Absolute Manage server."
        }, {
            "type": "sccm",
            "description": "Creates a cmmac package for deploying via "
                           "Microsoft SCCM."
        }, {
            "type": "ds",
            "description": "Imports into your DeployStudio Packages folder."
        }, {
            "type": "filewave",
            "description": "Imports a fileset into your FileWave server."
        })

    # Set default values for all recipe types.
    for recipe in recipes:
        recipe["preferred"] = True
        recipe["existing"] = False
        recipe["buildable"] = False

    return recipes


def init_prefs(prefs, recipes, args):
    """Read Recipe Robot preferences in the following priority order:
        0. If --config argument is specified, ignore prefs and rebuild.
        3. If preferences plist doesn't exist, rebuild.
        4. If preferences plist does exist, use it.

    Args:
        prefs: A dictionary containing a key/value pair for each preference.
            When this function is called for the first time, the prefs dict
            is typically empty.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.

    Returns:
        prefs: A fully populated preference dictionary.
    """

    prefs = {}
    global prefs_file

    # If prefs file exists, try to read from it.
    if os.path.isfile(prefs_file):

        # Open the file.
        try:
            prefs = FoundationPlist.readPlist(prefs_file)
        except Exception:
            robo_print("There was a problem opening the prefs file. Building "
                       "new preferences.", LogLevel.WARNING)
            prefs = build_prefs(prefs, recipes)

        for recipe in recipes:
            # Load preferred recipe types.
            if recipe["type"] in prefs["RecipeTypes"]:
                recipe["preferred"] = True
            else:
                recipe["preferred"] = False

        if args.config is True:
            robo_print("Showing configuration options...")
            prefs = build_prefs(prefs, recipes)

        # This seems to be necessary in order to avoid an error when reading
        # the plist back during subsequent runs.
        prefs["RecipeCreateCount"] = int(prefs["RecipeCreateCount"])

    else:
        robo_print("No prefs file found. Building new preferences...",
                   LogLevel.WARNING)
        prefs = build_prefs(prefs, recipes)

    # Record last version number.
    prefs["LastRecipeRobotVersion"] = __version__

    # Save preferences to disk for next time.
    FoundationPlist.writePlist(prefs, prefs_file)

    return prefs


def build_prefs(prefs, recipes):
    """Prompt user for preferences, then save them back to the plist.

    Args:
        prefs: The preference dictionary, passed from init_prefs().
        recipes: The list of known recipe types, created by init_recipes().

    Returns:
        prefs: The preference dictionary, newly populated from user input.
    """

    # Start recipe count at zero, if no value already exists.
    if "RecipeCreateCount" not in prefs:
        prefs["RecipeCreateCount"] = int(0)

    # Prompt for and save recipe identifier prefix.
    prefs["RecipeIdentifierPrefix"] = "com.github.homebysix"
    robo_print("\nRecipe identifier prefix")
    robo_print("This is your default identifier, in reverse-domain notation.\n")
    choice = raw_input(
        "[%s]: " % prefs["RecipeIdentifierPrefix"])
    if choice != "":
        prefs["RecipeIdentifierPrefix"] = str(choice).rstrip(". ")

    # Prompt for recipe creation location.
    prefs["RecipeCreateLocation"] = "~/Library/AutoPkg/Recipe Robot output"
    robo_print("\nLocation to save new recipes")
    robo_print("This is where on disk your newly created recipes will be saved.\n")
    choice = raw_input(
        "[%s]: " % prefs["RecipeCreateLocation"])
    if choice != "":
        prefs["RecipeCreateLocation"] = str(choice).rstrip("/ ")

    # Prompt to set recipe types on/off as desired.
    prefs["RecipeTypes"] = []
    robo_print("\nPreferred recipe types")
    robo_print("Choose which recipe types will be offered to you by default.\n")
    # TODO(Elliot): Make this interactive while retaining scrollback. (#17)
    # Maybe with curses module?
    while True:
        i = 0
        for recipe in recipes:
            if recipe["preferred"] is False:
                indicator = " "
            else:
                indicator = "*"
            robo_print("[%s] %s. %s - %s" %
                       (indicator, i, recipe["type"], recipe["description"]),
                       indent=2)
            i += 1
        robo_print("A. Enable all recipe types.", indent=6)
        robo_print("D. Disable all recipe types.", indent=6)
        robo_print("Q. Quit without saving changes.", indent=6)
        robo_print("S. Save changes and proceed.", indent=6)
        choice = raw_input(
            "\nType a number to toggle the corresponding recipe "
            "type between ON [*] and OFF [ ].\nWhen you're satisfied "
            "with your choices, type an \"S\" to save and proceed: ")
        if choice.upper() == "S":
            break
        elif choice.upper() == "A":
            for recipe in recipes:
                recipe["preferred"] = True
        elif choice.upper() == "D":
            for recipe in recipes:
                recipe["preferred"] = False
        elif choice.upper() == "Q":
            sys.exit(0)
        else:
            try:
                if recipes[int(choice)]["preferred"] is False:
                    recipes[int(choice)]["preferred"] = True
                else:
                    recipes[int(choice)]["preferred"] = False
            except Exception:
                robo_print("%s is not a valid option. Please try "
                           "again.\n" % choice, LogLevel.WARNING)

    # Set "preferred" status of each recipe type according to preferences.
    for recipe in recipes:
        if recipe["preferred"] is True:
            prefs["RecipeTypes"].append(recipe["type"])

            if recipe["type"] == "ds":
                prefs["DSPackagesPath"] = "/Shared/DeployStudio/Packages"
                robo_print("\nLocation of your DeployStudio packages:")
                robo_print("This where packages will be copied in order to "
                                  "appear in DeployStudio.\n")
                choice = raw_input(
                    "[%s]: " % prefs["DSPackagesPath"])
                if choice != "":
                    prefs["DSPackagesPath"] = str(choice).rstrip("/ ")

    return prefs


def process_input_path(input_path, args, facts):
    """Determine which functions to call based on the type of input path.

    Args:
        input_path: The path or URL that Recipe Robot was asked to use to
            create recipes.
        args: The command line arguments.
        facts: A continually-updated dictionary containing all the information
            we know so far about the app associated with the input path.
    """

    # Keep track of the inspections we perform, to make sure we don't loop.
    facts["inspections"] = []

    if input_path.startswith("http"):
        if (input_path.endswith(".xml") or
            input_path.endswith(".rss") or
            input_path.endswith(".php") or
            "appcast" in input_path):
            robo_print("Input path looks like a Sparkle feed.",
                       LogLevel.VERBOSE)
            facts = inspect_sparkle_feed_url(input_path, args, facts)
        elif ("github.com" in input_path or
              "githubusercontent.com" in input_path or
              "github.io" in input_path):
            robo_print("Input path looks like a GitHub URL.", LogLevel.VERBOSE)
            facts = inspect_github_url(input_path, args, facts)
        elif "sourceforge.net" in input_path:
            robo_print("Input path looks like a SourceForge URL.",
                       LogLevel.VERBOSE)
            facts = inspect_sourceforge_url(input_path, args, facts)
        elif "bitbucket.org" in input_path:
            robo_print("Input path looks like a BitBucket URL.",
                       LogLevel.VERBOSE)
            facts = inspect_bitbucket_url(input_path, args, facts)
        else:
            robo_print("Input path looks like a download URL.",
                       LogLevel.VERBOSE)
            facts = inspect_download_url(input_path, args, facts)
    elif input_path.startswith("ftp"):
        robo_print("Input path looks like a download URL.", LogLevel.VERBOSE)
        facts = inspect_download_url(input_path, args, facts)
    elif os.path.exists(input_path):
        if input_path.endswith(".app"):
            robo_print("Input path looks like an app.", LogLevel.VERBOSE)
            facts = inspect_app(input_path, args, facts)
        elif input_path.endswith(".recipe"):
            robo_print("Input path looks like a recipe.", LogLevel.VERBOSE)
            facts = inspect_recipe(input_path, args, facts)
        elif input_path.endswith(".pkg"):
            robo_print("Input path looks like a pkg.", LogLevel.VERBOSE)
            facts = inspect_pkg(input_path, args, facts)
        else:
            robo_print("I haven't been trained on how to handle this "
                       "input path:\n    %s" % input_path, LogLevel.ERROR)
    else:
        robo_print("Input path does not exist. Please try again with a "
                   "valid input path.", LogLevel.ERROR)


def get_app_description(app_name):
    """Use an app's name to generate a description from MacUpdate.com.

    Args:
        app_name: The name of the app that we need to describe.

    Returns:
        description: A string containing a description of the app.
    """

    # Start with an empty string. (If it remains empty, the parent function
    # will know that no description was available.)
    description = ""

    # This is the HTML immediately preceding the description text on the
    # MacUpdate search results page.
    description_marker = "-shortdescrip\">"

    cmd = "curl --silent \"http://www.macupdate.com/find/mac/%s\"" % app_name
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)

    # For each line in the resulting text, look for the description marker.
    html = out.split("\n")
    if exitcode == 0:
        for line in html:
            if description_marker in line:
                # Trim the HTML from the beginning of the line.
                start = line.find(description_marker) + len(description_marker)
                # Trim the HTML from the end of the line.
                description = line[start:].rstrip("</span>")
                # If we found a description, no need to process further lines.
                break
    else:
        robo_print("Error occurred while getting description from "
                   "MacUpdate: %s" % err, LogLevel.WARNING)

    return description


def inspect_github_url(input_path, args, facts):
    """Process a GitHub URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this GitHub URL yet.
    if "github_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("github_url")

    # Grab the GitHub repo path.
    github_repo = ""
    robo_print("Getting GitHub repo...", LogLevel.VERBOSE)
    # Matches all these examples:
    # [x] https://github.com/jbtule/cdto/releases/download/2_6_0/cdto_2_6.zip
    # [x] https://github.com/lindegroup/autopkgr
    # [x] https://raw.githubusercontent.com/macmule/AutoCasperNBI/master/README.md
    # [X] https://api.github.com/repos/macmule/AutoCasperNBI
    # [X] https://hjuutilainen.github.io/munkiadmin/
    github_repo = ""
    parsed_url = urlparse(input_path)
    path = parsed_url.path.split("/")
    path.remove("")
    if "api.github.com" in input_path:
        if "/repos/" not in input_path:
            robo_print("GitHub API URL specified is not a repository.",
                       LogLevel.WARNING)
        else:
            github_repo = path[1] + "/" + path[2]
    elif ".github.io" in input_path:
        github_repo = parsed_url.netloc.split(".")[0] + "/" + path[0]
    else:
        github_repo = path[0] + "/" + path[1]
    if github_repo != "":
        robo_print("GitHub repo is: %s" % github_repo, LogLevel.VERBOSE, 4)
        facts["github_repo"] = github_repo

        # TODO(Elliot): How can we use GitHub tokens to prevent rate limiting? (#18)

        # Use GitHub API to obtain information about the repo and releases.
        repo_api_url = "https://api.github.com/repos/%s" % github_repo
        releases_api_url = "https://api.github.com/repos/%s/releases/latest" % github_repo
        user_api_url = "https://api.github.com/users/%s" % github_repo.split("/")[0]

        # Download the information from the GitHub API.
        try:
            raw_json_repo = urlopen(repo_api_url).read()
            raw_json_release = urlopen(releases_api_url).read()
            raw_json_user = urlopen(user_api_url).read()
        except HTTPError as err:
            if err.code == 403:
                robo_print("Error occurred while getting information "
                           "from the GitHub API. If you've been creating a "
                           "lot of recipes quickly, you may have hit the "
                           "rate limit. Give it a few minutes, then try "
                           "again. (%s)" % err, LogLevel.WARNING)
                return facts
            if err.code == 404:
                robo_print("GitHub API URL not found. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error occurred while getting information "
                           "from the GitHub API. (%s)" % err, LogLevel.WARNING)
                return facts
        except URLError as err:
            if str(err.reason).startswith("[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]"):
                # TODO(Elliot): Try again using curl? (#19)
                robo_print("I got an SSLv3 handshake error while getting "
                           "information from the GitHub API, and I "
                           "don't yet know what to do with that. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error encountered while getting information "
                           "from the GitHub API. (%s)" % err, LogLevel.WARNING)
                return facts

        # Parse the downloaded JSON.
        parsed_repo = json.loads(raw_json_repo)
        parsed_release = json.loads(raw_json_release)
        parsed_user = json.loads(raw_json_user)

        # Get app name.
        if "app_name" not in facts:
            app_name = ""
            robo_print("Getting app name...", LogLevel.VERBOSE)
            if "name" in parsed_repo:
                if parsed_repo["name"] is not None:
                    app_name = parsed_repo["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Get app description.
        if "description" not in facts:
            description = ""
            robo_print("Getting GitHub description...", LogLevel.VERBOSE)
            if "description" in parsed_repo:
                if parsed_repo["description"] is not None:
                    description = parsed_repo["description"]
            if description != "":
                robo_print("GitHub description is: %s" % description,
                           LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("No GitHub description provided.",
                           LogLevel.WARNING)

        # Get download format of latest release.
        if "download_format" not in facts or "download_url" not in facts:
            download_format = ""
            download_url = ""
            robo_print("Getting information from latest GitHub release...",
                       LogLevel.VERBOSE)
            if "assets" in parsed_release:
                for asset in parsed_release["assets"]:
                    for this_format in all_supported_formats:
                        if asset["browser_download_url"].endswith(this_format):
                            download_format = this_format
                            download_url = asset["browser_download_url"]
                            break
            if download_format != "":
                robo_print("GitHub release download format "
                           "is: %s" % download_format,
                           LogLevel.VERBOSE, 4)
                facts["download_format"] = download_format
            else:
                robo_print("Could not detect GitHub release download format.",
                           LogLevel.WARNING)
            if download_url != "":
                robo_print("GitHub release download URL "
                           "is: %s" % download_url, LogLevel.VERBOSE, 4)
                facts["download_url"] = download_url
                inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect GitHub release download URL.",
                           LogLevel.WARNING)

        # Get the developer's name from GitHub.
        if "developer" not in facts:
            developer = ""
            robo_print("Getting developer name from GitHub...",
                       LogLevel.VERBOSE)
            if "name" in parsed_user:
                developer = parsed_user["name"]
            if developer != "":
                robo_print("GitHub developer "
                           "is: %s" % developer, LogLevel.VERBOSE, 4)
                facts["developer"] = developer
            else:
                robo_print("Could not detect GitHub developer.",
                           LogLevel.WARNING)

        # Warn user if the GitHub project is private.
        if "private" in parsed_repo:
            if parsed_repo["private"] is True:
                robo_print("This GitHub project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

        # Warn user if the GitHub project is a fork.
        if "private" in parsed_repo:
            if parsed_repo["fork"] is True:
                robo_print("This GitHub project is a fork. You may want to "
                           "try again with the original repo URL instead.", LogLevel.WARNING)
    else:
        robo_print("Could not detect GitHub repo.", LogLevel.WARNING)

    return facts


def inspect_sourceforge_url(input_path, args, facts):
    """Process a SourceForge URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this SourceForge URL yet.
    if "sourceforge_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("sourceforge_url")

    # Determine the name of the SourceForge project.
    proj_name = ""
    if  "/projects/" in input_path:
        # Example: http://sourceforge.net/projects/adium/?source=recommended
        # Example: http://sourceforge.net/projects/grandperspectiv
        # Example: http://sourceforge.net/projects/grandperspectiv/
        marker = "/projects/"
        proj_str = input_path[input_path.find(marker) + len(marker):]
        if proj_str.find("/") > 0:
            proj_name = proj_str[:proj_str.find("/")]
        else:
            proj_name = proj_str
    elif "/p/" in input_path:
        # Example: http://sourceforge.net/p/grandperspectiv/wiki/Home/
        marker = "/p/"
        proj_str = input_path[input_path.find(marker) + len(marker):]
        if proj_str.find("/") > 0:
            proj_name = proj_str[:proj_str.find("/")]
        else:
            proj_name = proj_str
    elif ".sourceforge.net" in input_path:
        # Example: http://grandperspectiv.sourceforge.net/
        # Example: http://grandperspectiv.sourceforge.net/screenshots.html
        marker = ".sourceforge.net"
        proj_str = input_path.lstrip("http://")
        proj_name = proj_str[:proj_str.find(marker)]
    else:
        robo_print("Unable to parse SourceForge URL.", LogLevel.WARNING)
    if proj_name != "":

        # Use SourceForge API to obtain project information.
        project_api_url = "https://sourceforge.net/rest/p/" + proj_name
        try:
            raw_json = urlopen(project_api_url).read()
        except HTTPError as err:
            if err.code == 403:
                robo_print("Error occurred while getting information "
                           "from the SourceForge API. If you've been creating a "
                           "lot of recipes quickly, you may have hit the "
                           "rate limit. Give it a few minutes, then try "
                           "again. (%s)" % err, LogLevel.WARNING)
                return facts
            if err.code == 404:
                robo_print("SourceForge API URL not found. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error occurred while getting information "
                           "from the SourceForge API. (%s)" % err, LogLevel.WARNING)
                return facts
        except URLError as err:
            if str(err.reason).startswith("[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]"):
                # TODO(Elliot): Try again using curl? (#19)
                robo_print("I got an SSLv3 handshake error while getting "
                           "information from the SourceForge API, and I "
                           "don't yet know what to do with that. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error encountered while getting information "
                           "from the SourceForge API. (%s)" % err, LogLevel.WARNING)
                return facts
        parsed_json = json.loads(raw_json)

        # Get app name.
        if "app_name" not in facts:
            if "shortname" in parsed_json or "name" in parsed_json:
                # Record the shortname, if shortname isn't blank.
                if parsed_json["shortname"] != "":
                    app_name = parsed_json["shortname"]
                # Overwrite the shortname with name, if name isn't blank.
                if parsed_json["name"] != "":
                    app_name = parsed_json["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Determine project ID.
        proj_id = ""
        robo_print("Getting SourceForge project ID...", LogLevel.VERBOSE)
        for this_dict in parsed_json["tools"]:
            if "sourceforge_group_id" in this_dict:
                proj_id = this_dict["sourceforge_group_id"]
        if proj_id != "":
            robo_print("SourceForge project ID is: %s" % proj_id, LogLevel.VERBOSE, 4)
            facts["sourceforge_id"] = proj_id
        else:
            robo_print("Could not detect SourceForge project ID.", LogLevel.WARNING)

        # Get project description.
        if "description" not in facts:
            description = ""
            robo_print("Getting SourceForge description...", LogLevel.VERBOSE)
            if "summary" in parsed_json:
                if parsed_json["summary"] != "":
                    description = parsed_json["summary"]
                elif parsed_json["short_description"] != "":
                    description = parsed_json["short_description"]
            if description != "":
                robo_print("SourceForge description is: %s" % description, LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("Could not detect SourceForge description.", LogLevel.WARNING)

        # Get download format of latest release.
        if "download_url" not in facts:

            # Download the RSS feed and parse it.
            # Example: http://sourceforge.net/projects/grandperspectiv/rss
            # Example: http://sourceforge.net/projects/cord/rss
            # TODO(Elliot): Per SourceForge TOS we should limit RSS
            # requests to one hit per 30 minute period per feed. (#20)
            files_rss = "http://sourceforge.net/projects/%s/rss" % proj_name
            try:
                raw_xml = urlopen(files_rss)
            except Exception as err:
                robo_print("Error occured while inspecting SourceForge RSS "
                           "feed: %s" % err, LogLevel.WARNING)
            doc = parse(raw_xml)

            # Get the latest download URL.
            download_url = ""
            robo_print("Determining download URL from SourceForge RSS feed...", LogLevel.VERBOSE)
            for item in doc.iterfind('channel/item'):
                # TODO(Elliot): The extra-info tag is not a reliable indicator
                # of which item should actually be downloaded. (#21)
                # Example: http://sourceforge.net/projects/grandperspectiv/rss
                search = "{https://sourceforge.net/api/files.rdf#}extra-info"
                if item.find(search).text.startswith("data"):
                    download_url = item.find("link").text.rstrip("/download")
                    break
            if download_url != "":
                facts = inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect SourceForge latest release download_url.", LogLevel.WARNING)

        # Warn user if the SourceForge project is private.
        if "private" in parsed_json:
            if parsed_json["private"] is True:
                robo_print("This SourceForge project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

    else:
        robo_print("Could not detect SourceForge project name.", LogLevel.WARNING)

    return facts


def inspect_bitbucket_url(input_path, args, facts):
    """Process a BitBucket URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this BitBucket URL yet.
    if "bitbucket_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("bitbucket_url")

    # Grab the BitBucket repo path.
    bitbucket_repo = ""
    robo_print("Getting BitBucket repo...", LogLevel.VERBOSE)
    r_obj = re.search(r"(?<=https://bitbucket\.org/)[\w-]+/[\w-]+", input_path)
    if r_obj is not None:
        bitbucket_repo = r_obj.group(0)
    if bitbucket_repo != "":
        robo_print("BitBucket repo is: %s" % bitbucket_repo, LogLevel.VERBOSE, 4)
        facts["bitbucket_repo"] = bitbucket_repo

        # Use GitHub API to obtain information about the repo and releases.
        repo_api_url = "https://api.bitbucket.org/2.0/repositories/%s" % bitbucket_repo
        releases_api_url = "https://api.bitbucket.org/2.0/repositories/%s/downloads" % bitbucket_repo
        try:
            raw_json_repo = urlopen(repo_api_url).read()
            parsed_repo = json.loads(raw_json_repo)
            raw_json_release = urlopen(releases_api_url).read()
            parsed_release = json.loads(raw_json_release)
        except HTTPError as err:
            if err.code == 403:
                robo_print("Error occurred while getting information "
                           "from the BitBucket API. If you've been creating a "
                           "lot of recipes quickly, you may have hit the "
                           "rate limit. Give it a few minutes, then try "
                           "again. (%s)" % err, LogLevel.WARNING)
                return facts
            if err.code == 404:
                robo_print("BitBucket API URL not found. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error occurred while getting information "
                           "from the BitBucket API. (%s)" % err, LogLevel.WARNING)
                return facts
        except URLError as err:
            if str(err.reason).startswith("[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]"):
                # TODO(Elliot): Try again using curl? (#19)
                robo_print("I got an SSLv3 handshake error while getting "
                           "information from the BitBucket API, and I "
                           "don't yet know what to do with that. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
            else:
                robo_print("Error encountered while getting information "
                           "from the BitBucket API. (%s)" % err, LogLevel.WARNING)
                return facts

        # Get app name.
        if "app_name" not in facts:
            app_name = ""
            robo_print("Getting app name...", LogLevel.VERBOSE)
            if "name" in parsed_repo:
                if parsed_repo["name"] != "":
                    app_name = parsed_repo["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Get full name of owner.
        developer = ""
        if "developer" not in facts:
            developer = parsed_repo["owner"]["display_name"]
        if developer != "":
            robo_print("BitBucket owner full name "
                       "is: %s" % developer, LogLevel.VERBOSE, 4)
            facts["developer"] = developer

        # Get app description.
        if "description" not in facts:
            description = ""
            robo_print("Getting BitBucket description...", LogLevel.VERBOSE)
            if "description" in parsed_repo:
                if parsed_repo["description"] != "":
                    description = parsed_repo["description"]
            if description != "":
                robo_print("BitBucket description is: %s" % description, LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("Could not detect BitBucket description.", LogLevel.WARNING)

        # Get download format of latest release.
        if "download_format" not in facts or "download_url" not in facts:
            download_format = ""
            download_url = ""
            robo_print("Getting information from latest BitBucket release...", LogLevel.VERBOSE)
            if "values" in parsed_release:
                for asset in parsed_release["values"]:
                    for this_format in all_supported_formats:
                        if asset["links"]["self"]["href"].endswith(this_format):
                            download_format = this_format
                            download_url = asset["links"]["self"]["href"]
                            break
            if download_format != "":
                robo_print("BitBucket release download format "
                           "is: %s" % download_format, LogLevel.VERBOSE, 4)
                facts["download_format"] = download_format
            else:
                robo_print("Could not detect BitBucket release download format.", LogLevel.WARNING)
            if download_url != "":
                robo_print("BitBucket release download URL "
                           "is: %s" % download_url, LogLevel.VERBOSE, 4)
                facts["download_url"] = download_url
                inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect BitBucket release download URL.", LogLevel.WARNING)

        # Warn user if the BitBucket project is private.
        if "is_private" in parsed_repo:
            if parsed_repo["is_private"] is True:
                robo_print("This BitBucket project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

    else:
        robo_print("Could not detect BitBucket repo.", LogLevel.WARNING)

    return facts


def inspect_sparkle_feed_url(input_path, args, facts):
    """Process a Sparkle feed URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this Sparkle feed yet.
    if "sparkle_feed_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("sparkle_feed_url")

    # Save the Sparkle feed URL to the dictionary of facts.
    robo_print("Sparkle feed is: %s" % input_path, LogLevel.VERBOSE, 4)
    facts["sparkle_feed"] = input_path

    # Download the Sparkle feed.
    try:
        raw_xml = urlopen(input_path)
    except HTTPError as err:
        if err.code == 403:
            # Try again, this time with a user-agent.
            try:
                opener = build_opener()
                opener.addheaders = [('User-agent', 'Mozilla/5.0')]
                raw_xml = opener.open(input_path)
                robo_print("I had to use a different user-agent in order to "
                           "read this Sparkle feed. If you run the recipes and "
                           "get a \"Can't open URL\" error, it means AutoPkg "
                           "encountered the same problem.", LogLevel.WARNING)
                facts["user-agent"] = "Mozilla/5.0"
            except Exception as err:
                robo_print("Error occured while downloading Sparkle feed (%s)" % err, LogLevel.WARNING)
                # Remove Sparkle feed if it's not usable.
                facts.pop("sparkle_feed", None)
                return facts
        if err.code == 404:
            robo_print("Sparkle feed not found. "
                       "(%s)" % err, LogLevel.WARNING)
            facts.pop("sparkle_feed", None)
            return facts
        else:
            robo_print("Error occurred while getting information "
                       "from the Sparkle feed. (%s)" % err, LogLevel.WARNING)
            facts.pop("sparkle_feed", None)
            return facts
    except URLError as err:
        if str(err.reason).startswith("[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]"):
            # TODO(Elliot): Try again using curl? (#19)
            robo_print("I got an SSLv3 handshake error while getting "
                       "information from the Sparkle feed, and I "
                       "don't yet know what to do with that. "
                       "(%s)" % err, LogLevel.WARNING)
            facts.pop("sparkle_feed", None)
            return facts
        else:
            robo_print("Error encountered while getting information "
                       "from the Sparkle feed. (%s)" % err, LogLevel.WARNING)
            facts.pop("sparkle_feed", None)
            return facts

    # Parse the Sparkle feed.
    try:
        doc = parse(raw_xml)
    except ParseError as err:
        robo_print("Error occured while parsing Sparkle feed (%s)" % err, LogLevel.WARNING)
        facts.pop("sparkle_feed", None)
        return facts

    # TODO(Elliot): Handle custom namespaces. (#22) Example code:
    # https://github.com/autopkg/autopkg/blob/master/Code/autopkglib/SparkleUpdateInfoProvider.py#L115-L119
    xmlns = "http://www.andymatuschak.org/xml-namespaces/sparkle"

    # Determine whether the Sparkle feed provides a version number.
    sparkle_provides_version = False
    latest_version = "0"
    latest_url = ""
    robo_print("Getting information from Sparkle feed...", LogLevel.VERBOSE)
    for item in doc.iterfind('channel/item/enclosure'):
        if item.get("{%s}shortVersionString" % xmlns) is not None:
            sparkle_provides_version = True
            if LooseVersion(item.get("{%s}shortVersionString" % xmlns)) > LooseVersion(latest_version):
                latest_version = item.get("{%s}shortVersionString" % xmlns)
                latest_url = item.attrib["url"]
        if item.get("{%s}version" % xmlns) is not None:
            sparkle_provides_version = True
            if LooseVersion(item.get("{%s}version" % xmlns)) > LooseVersion(latest_version):
                latest_version = item.get("{%s}version" % xmlns)
                latest_url = item.attrib["url"]
    if sparkle_provides_version is True:
        robo_print("The Sparkle feed provides a version "
                   "number", LogLevel.VERBOSE, 4)
    else:
        robo_print("The Sparkle feed does not provide a version "
                   "number", LogLevel.VERBOSE, 4)
    facts["sparkle_provides_version"] = sparkle_provides_version
    if latest_version != "":
        robo_print("The latest version is %s" % latest_version, LogLevel.VERBOSE, 4)
    if latest_url != "":
        facts = inspect_download_url(latest_url, args, facts)

    # If Sparkle feed is hosted on GitHub or SourceForge, we can gather more
    # information.
    if "github.com" in input_path or "githubusercontent.com" in input_path:
        if "github_repo" not in facts:
            facts = inspect_github_url(input_path, args, facts)
    if "sourceforge.net" in input_path:
        if "sourceforge_id" not in facts:
            facts = inspect_sourceforge_url(input_path, args, facts)

    return facts


def inspect_download_url(input_path, args, facts):
    """Process a direct download URL, gathering required information to
    create a recipe.
    """

    # We never skip download URL inspection, even if we've already inspected
    # a download URL during this run. This handles rare situations in which
    # the download URL is in a different format than the Sparkle download.
    # Example: http://rdio0-a.akamaihd.net/media/static/desktop/mac/Rdio.dmg

    # Strip leading and trailing spaces, then change remaining spaces to "%20".
    input_path = input_path.lstrip(" ").rstrip(" ").replace(" ", "%20")

    # Save the download URL to the dictionary of facts.
    robo_print("Download URL is: %s" % input_path, LogLevel.VERBOSE, 4)
    facts["download_url"] = input_path
    facts["is_from_app_store"] = False

    # If download URL is hosted on GitHub or SourceForge, we can gather more
    # information.
    if "github.com" in input_path or "githubusercontent.com" in input_path:
        if "github_repo" not in facts:
            facts = inspect_github_url(input_path, args, facts)
    if "sourceforge.net" in input_path:
        if "sourceforge_id" not in facts:
            facts = inspect_sourceforge_url(input_path, args, facts)

    # Warn if it looks like we're using a version-specific download path, but
    # only if the path was not obtained from a feed of some sort.
    version_match = re.search(r"[\d]+\.[\w]+$", input_path)
    if version_match is not None and ("sparkle_feed_url" not in facts["inspections"] and
                                      "github_url" not in facts["inspections"] and
                                      "sourceforge_url" not in facts["inspections"] and
                                      "bitbucket_url" not in facts["inspections"]):
        robo_print("Careful, this might be a version-specific URL. Better to "
                   "give me a \"-latest\" URL or a Sparkle "
                   "feed.", LogLevel.WARNING)

    # Determine filename from input URL (will be overridden later if a better
    # candidate is found.)
    parsed_url = urlparse(input_path)
    filename = parsed_url.path.split("/")[-1]

    # Download the file for continued inspection.
    # TODO(Elliot): Maybe something like this is better for downloading big
    # files? https://gist.github.com/gourneau/1430932 (#24)
    robo_print("Downloading file for further inspection...", LogLevel.VERBOSE)
    create_dest_dirs(cache_dir)

    # Actually download the file.
    try:
        raw_download = urlopen(input_path)
    except HTTPError as err:
        if err.code == 403:
            # Try again, this time with a user-agent.
            try:
                opener = build_opener()
                opener.addheaders = [('User-agent', 'Mozilla/5.0')]
                raw_download = opener.open(input_path)
                robo_print("I had to use a different user-agent in order to "
                           "download this file. If you run the recipes and get a "
                           "\"Can't open URL\" error, it means AutoPkg "
                           "encountered the same problem.", LogLevel.WARNING)
                facts["user-agent"] = "Mozilla/5.0"
            except Exception as err:
                robo_print("Error encountered during file download. "
                           "(%s)" % err, LogLevel.WARNING)
                return facts
        if err.code == 404:
            robo_print("Download URL not found. (%s)" % err, LogLevel.WARNING)
            return facts
        else:
            robo_print("Error encountered during file download. "
                       "(%s)" % err, LogLevel.WARNING)
            return facts
    except URLError as err:
        if str(err.reason).startswith("[SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]"):
            # TODO(Elliot): Try again using curl? (#19)
            robo_print("I got an SSLv3 handshake error, and I don't yet know "
                       "what to do with that. (%s)" % err, LogLevel.WARNING)
            return facts
        else:
            robo_print("Error encountered during file download. "
                       "(%s)" % err.reason, LogLevel.WARNING)
            return facts

    # Get the actual filename from the server, if it exists.
    if "Content-Disposition" in raw_download.info():
        content_disp = raw_download.info()["Content-Disposition"]
        r_obj = re.search(r"filename=\"(.+)\"\;", content_disp)
        if r_obj is not None:
            filename = r_obj.group(1)

    # If filename was not detected from either the URL or the headers, use a
    # safe default name.
    if filename == "":
        filename = "download"
    facts["download_filename"] = filename

    # Write the downloaded file to the cache folder.
    with open(os.path.join(cache_dir, filename), "wb") as download_file:
        download_file.write(raw_download.read())
        robo_print("Downloaded to %s" % os.path.join(cache_dir, filename), LogLevel.VERBOSE, 4)

    # Just in case the "download" was actually a Sparkle feed.
    hidden_sparkle = False
    with open(os.path.join(cache_dir, filename), "r") as download_file:
        if download_file.read()[:6] == "<?xml ":
            robo_print("This download is actually a Sparkle "
                       "feed", LogLevel.VERBOSE, 4)
            hidden_sparkle = True
    if hidden_sparkle is True:
        os.remove(os.path.join(cache_dir, filename))
        inspect_sparkle_feed_url(input_path, args, facts)
        return facts

    # Try to determine the type of file downloaded. (Overwrites any previous
    # download_type, because the download URL is the most reliable source.)
    download_format = ""
    robo_print("Determining download format...", LogLevel.VERBOSE)
    for this_format in all_supported_formats:
        if filename.lower().endswith(this_format):
            download_format = this_format
            robo_print("File extension is %s" % this_format, LogLevel.VERBOSE, 4)
            break  # should stop after the first format match
        if this_format in parsed_url.query:
            download_format = this_format
            robo_print("File extension is %s" % this_format, LogLevel.VERBOSE, 4)
            break  # should stop after the first format match

    # If we've already seen the app and the download format, there's no need
    # to unpack the downloaded file.
    if "download_format" in facts and "app" in facts["inspections"]:
        return facts

    robo_print("Opening downloaded file...", LogLevel.VERBOSE)

    # Open the disk image (or test to see whether the download is one).
    if download_format == "" or download_format in supported_image_formats:

        # Determine whether the dmg has a software license agreement.
        # Inspired by: https://github.com/autopkg/autopkg/blob/master/Code/autopkglib/DmgMounter.py#L74-L98
        dmg_has_sla = False
        cmd = "/usr/bin/hdiutil imageinfo -plist \"%s\"" % os.path.join(cache_dir, filename)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:
            with open(os.path.join(cache_dir, "dmg_info.plist"), "wb") as dmg_plist:
                dmg_plist.write(out)
            try:
                dmg_info = FoundationPlist.readPlist(os.path.join(cache_dir, "dmg_info.plist"))
                if dmg_info.get("Properties").get("Software License Agreement") == True:
                    dmg_has_sla = True
            except FoundationPlist.NSPropertyListSerializationException:
                pass
        if dmg_has_sla is True:
            robo_print("Please type Y and press Enter to accept the software license agreement.", LogLevel.WARNING)

        # TODO(Elliot): Make the SLA non-interactive. (#25)
        # Example: https://github.com/autopkg/autopkg/blob/master/Code/autopkglib/DmgMounter.py#L108-L110

        # Mount the dmg and look for an app.
        cmd = "/usr/bin/hdiutil attach -plist \"%s\"" % os.path.join(cache_dir, filename)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was a disk image. Make a note of that.
            if download_format == "":
                download_format = "dmg"  # most common disk image format
            robo_print("Successfully mounted %s" % download_format, LogLevel.VERBOSE, 4)
            facts["download_format"] = download_format

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_image_formats):
                facts["download_filename"] = facts["download_filename"] + ".dmg"

            # Clean the output for cases where the dmg has a license agreement.
            out_clean = out[out.find("<?xml"):]

            # Locate and inspect the app.
            with open(os.path.join(cache_dir, "dmg_attach.plist"), "wb") as dmg_plist:
                dmg_plist.write(out_clean)
            try:
                dmg_dict = FoundationPlist.readPlist(os.path.join(cache_dir, "dmg_attach.plist"))
            except Exception:
                robo_print("Shoot, I had trouble parsing the output of "
                           "hdiutil while mounting the downloaded dmg. Sorry "
                           "about that.", LogLevel.ERROR)
            for entity in dmg_dict["system-entities"]:
                if "mount-point" in entity:
                    dmg_mount = entity["mount-point"]
                    break
            for this_file in os.listdir(dmg_mount):
                if this_file.endswith(".app"):
                    # Copy app to cache folder.
                    # TODO(Elliot): What if .app isn't on root of dmg mount? (#26)
                    attached_app_path = os.path.join(dmg_mount, this_file)
                    cached_app_path = os.path.join(cache_dir, "unpacked", this_file)
                    if not os.path.exists(cached_app_path):
                        try:
                            shutil.copytree(attached_app_path, cached_app_path)
                        except shutil.Error:
                            pass
                    # Unmount attached volume when done.
                    cmd = "/usr/bin/hdiutil detach \"%s\"" % dmg_mount
                    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
                    facts = inspect_app(cached_app_path, args, facts)
                    break
                if this_file.endswith(".pkg") or this_file.endswith(".mpkg"):
                    inspect_pkg(os.path.join(dmg_mount, this_file), args, facts)
                    break

    # Open the zip archive (or test to see whether the download is one).
    if download_format == "" or download_format in supported_archive_formats:

        # Unzip the zip and look for an app.
        cmd = "/usr/bin/unzip \"%s\" -d \"%s\"" % (os.path.join(cache_dir, filename), os.path.join(cache_dir, "unpacked"))
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was an archive. Make a note of that.
            if download_format == "":
                download_format = "zip"  # most common archive format
            robo_print("Successfully unzipped %s" % download_format, LogLevel.VERBOSE, 4)
            facts["download_format"] = download_format

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_archive_formats):
                facts["download_filename"] = facts["download_filename"] + ".zip"

            # Locate and inspect the app.
            for this_file in os.listdir(os.path.join(cache_dir, "unpacked")):
                if this_file.endswith(".app"):
                    # TODO(Elliot): What if .app isn't on root of zip? (#26)
                    # Example: https://github.com/jbtule/cdto/releases/download/2_6_0/cdto_2_6.zip
                    facts = inspect_app(os.path.join(cache_dir, "unpacked", this_file), args, facts)
                    break
                if this_file.endswith(".pkg") or this_file.endswith(".mpkg"):
                    inspect_pkg(os.path.join(cache_dir, "unpacked", this_file), args, facts)
                    break

    # Open the tar archive (or test to see whether the download is one).
    if download_format == "" or download_format in supported_archive_formats:

        # Unzip the tgz and look for an app.
        cmd = "/usr/bin/tar -zxvf \"%s\" -C \"%s\"" % (os.path.join(cache_dir, filename), os.path.join(cache_dir, "unpacked"))
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was an archive. Make a note of that.
            if download_format == "":
                download_format = "tgz"
            robo_print("Successfully unzipped %s" % download_format, LogLevel.VERBOSE, 4)
            facts["download_format"] = download_format

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_archive_formats):
                facts["download_filename"] = facts["download_filename"] + ".tgz"

            # Locate and inspect the app.
            for this_file in os.listdir(os.path.join(cache_dir, "unpacked")):
                if this_file.endswith(".app"):
                    # TODO(Elliot): What if .app isn't on root of tgz? (#26)
                    facts = inspect_app(os.path.join(cache_dir, "unpacked", this_file), args, facts)
                    break
                if this_file.endswith(".pkg") or this_file.endswith(".mpkg"):
                    inspect_pkg(os.path.join(cache_dir, "unpacked", this_file), args, facts)
                    break

    # Inspect the installer (or test to see whether the download is one).
    if download_format in supported_install_formats:

        robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)
        facts["download_format"] = download_format

        # Inspect the package.
        inspect_pkg(os.path.join(cache_dir, filename), args, facts)

    if download_format == "":
        robo_print("I've investigated pretty thoroughly, and I'm still not "
                   "sure what the download format is. This could cause "
                   "problems later.", LogLevel.WARNING)

    return facts


def inspect_pkg(input_path, args, facts):
    """Process a package, gathering required information to create a recipe.
    """

    # Only proceed if we haven't inspected this pkg yet.
    if "pkg" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("pkg")

    # Check whether package is signed.
    robo_print("Checking whether package is signed...", LogLevel.VERBOSE)
    cmd = "/usr/sbin/pkgutil --check-signature \"%s\"" % input_path
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    if exitcode == 1:
        robo_print("Package is not signed", LogLevel.VERBOSE, 4)
        facts["pkgsign_status"] = "unsigned"
    elif exitcode == 0:
        robo_print("Package is signed", LogLevel.VERBOSE, 4)
        facts["pkgsign_status"] = "signed"

        # Get developer name from pkg signature.
        if "developer" not in facts:
            developer = ""
            robo_print("Getting developer from pkg signature...", LogLevel.VERBOSE)
            marker = "    1. Developer ID Installer: "
            for line in out.split("\n"):
                if line.startswith(marker):
                    if " (" in line:
                        line = line.split(" (")[0]
                    developer = line[len(marker):]
            if developer != "":
                robo_print("Developer is: %s" % developer, LogLevel.VERBOSE, 4)
                facts["developer"] = developer
            else:
                robo_print("Developer is unknown", LogLevel.VERBOSE, 4)

        # Get code signature verification requirements from pkg signature.
        if "pkgsign_reqs" not in facts:
            pkgsign_reqs = []
            robo_print("Getting package signature verification requirements...", LogLevel.VERBOSE)
            for line in out.split("\n"):
                if re.match("^    [\d]\. ", line):
                    pkgsign_reqs.append(line[7:])
            if pkgsign_reqs != []:
                robo_print("%s requirements recorded" % len(pkgsign_reqs), LogLevel.VERBOSE, 4)
                facts["pkgsign_reqs"] = pkgsign_reqs
            else:
                robo_print("Requirements unknown", LogLevel.VERBOSE, 4)
                # Better to treat the package as unsigned, then.
                facts["pkgsign_status"] = "unsigned"

    else:
        robo_print("I don't know whether the package is signed - probably not "
                   "(pkgutil returned exit code %s)" % exitcode, LogLevel.VERBOSE, 4)

    # Expand the flat package and look for more facts.
    robo_print("Expanding package to look for clues...", LogLevel.VERBOSE)
    expand_path = os.path.join(cache_dir, "expanded")
    if os.path.exists(expand_path):
        shutil.rmtree(expand_path)
    cmd = "/usr/sbin/pkgutil --expand \"%s\" \"%s\"" % (input_path, expand_path)
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    if exitcode == 0:
        # Locate and inspect the app.
        robo_print("Package expanded to: %s" % os.path.join(cache_dir, "expanded"), LogLevel.VERBOSE, 4)
        install_filename = ""
        for dirpath, dirnames, filenames in os.walk("%s" % os.path.join(cache_dir, "expanded")):
            for dirname in dirnames:
                if dirname.startswith("."):
                    dirnames.remove(dirname)
            for filename in filenames:

                if filename == "PackageInfo":
                    robo_print("Getting information from PackageInfo file...", LogLevel.VERBOSE)
                    pkginfo_file = open(os.path.join(cache_dir, "expanded", dirpath, filename), "r")
                    pkginfo_parsed = parse(pkginfo_file)

                    bundle_id = ""
                    if "bundle_id" not in facts:
                        bundle_id = pkginfo_parsed.getroot().attrib["identifier"]
                    if bundle_id != "":
                        robo_print("Bundle identifier: %s" % bundle_id, LogLevel.VERBOSE, 4)
                        facts["bundle_id"] = bundle_id

                    install_loc = pkginfo_parsed.getroot().attrib["install-location"]
                    robo_print("Install location: %s" % install_loc, LogLevel.VERBOSE, 4)

                    install_filename = os.path.basename(install_loc)
                    robo_print("Install filename: %s" % install_filename, LogLevel.VERBOSE, 4)
                    continue  # TODO(Elliot): Or should we stop after the first? (#27)

                if filename == "Payload":
                    # We found a payload. Let's peek inside and see if there's an
                    # app.
                    robo_print("Extracting the package payload to see if we "
                               "can find an app...", LogLevel.VERBOSE)
                    app_found = False
                    payload_path = os.path.join(cache_dir, "expanded", dirpath, filename)
                    if install_filename.endswith(".app"):
                        extracted_app_path = os.path.join(cache_dir, "extracted_apps", install_filename)
                        if os.path.exists(extracted_app_path):
                            shutil.rmtree(extracted_app_path)
                        cmd = "/usr/bin/gunzip -c \"%s\" | pax -r -s \",./,%s/,\"" % (payload_path, extracted_app_path)
                        # TODO(Elliot): This doesn't work because it's outside the working directory. (#27)
                        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
                        if exitcode == 0:
                            app_found = True
                            robo_print("Found app: %s" % extracted_app_path, LogLevel.VERBOSE, 4)
                            inspect_app(extracted_app_path, args, facts)
                            break  # Struck pay dirt, so stop iterating
                                   # through apps in the payload
                        else:
                            robo_print("Error extracting the payload. (%s)" % err, LogLevel.VERBOSE, 4)

                    elif install_filename == "":

                        cmd = "/usr/bin/gunzip -c \"%s\" | pax" % payload_path
                        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
                        if exitcode == 0:
                            out = out.split("\n")
                            for line in out:
                                    app_found = True
                                    robo_print("Found app: %s" % line, LogLevel.VERBOSE, 4)
                                    extracted_app_path = os.path.join(cache_dir, "extracted_apps", os.path.split(line)[1])
                                    cmd = "/usr/bin/gunzip -c \"%s\" | pax -r -s \",%s,%s,\"" % (os.path.join(cache_dir, "expanded", filename), line, extracted_app_path)
                                    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
                                    if exitcode == 0:
                                        inspect_app(extracted_app_path, args, facts)
                                        break  # Struck pay dirt, so stop iterating
                                               # through apps in the payload
                                        # TODO(Elliot): Should we stop at the first app? (#27)
                                        # Find multiple, but use the one with the shortest path?
                                        # Find multiple, but use the largest file size?
                                        # Inspect all of them, use only the one with a Sparkle feed?
                                    else:
                                        robo_print("Error while extracting the package payload. "
                                                   "(%s)" % err, LogLevel.VERBOSE, 4)
                        else:
                            robo_print("Error while examining the package payload. "
                                       "(%s)" % err, LogLevel.VERBOSE, 4)

                    if app_found is False:
                        robo_print("Did not find an app in the package "
                                   "payload", LogLevel.VERBOSE, 4)
                    break  # Once we're done examining the Payload, there's not
                           # much else we can examine.

                if filename.endswith(".app"):
                    inspect_app(filename, args, facts)
                    break  # Struck pay dirt, so stop iterating through files
                           # in the package

    else:
        robo_print("Unable to expand package", LogLevel.VERBOSE, 4)

    # TODO(Elliot): What info do we need to gather to produce recipes here? (#27)

    return facts


def inspect_app(input_path, args, facts):
    """Process an app, gathering required information to create a recipe.
    """

    # Only proceed if we haven't inspected this app yet.
    if "app" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("app")

    # Save the path of the app. (Used when overriding AppStoreApp recipes.)
    facts["app_path"] = input_path

    # Read the app's Info.plist.
    robo_print("Validating app...", LogLevel.VERBOSE)
    try:
        info_plist = FoundationPlist.readPlist(input_path + "/Contents/Info.plist")
        robo_print("App seems valid", LogLevel.VERBOSE, 4)
    except Exception:
        robo_print("%s doesn't look like a valid app to me." % input_path, LogLevel.ERROR)

    # Get the filename of the app (which is usually the same as the app name.)
    app_file = os.path.basename(input_path)[:-4]

    # Determine the name of the app. (Overwrites any previous app_name, because
    # the app Info.plist itself is the most reliable source.)
    app_name = ""
    robo_print("Getting app name...", LogLevel.VERBOSE)
    if "CFBundleName" in info_plist:
        app_name = info_plist["CFBundleName"]
    elif "CFBundleExecutable" in info_plist:
        app_name = info_plist["CFBundleExecutable"]
    else:
        app_name = app_file
    robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
    facts["app_name"] = app_name

    # If the app's filename is different than the app's name, we need to make
    # a note of that. Many recipes require another input variable for this.
    if app_name != app_file:
        robo_print("App name differs from the actual app filename.", LogLevel.VERBOSE)
        robo_print("Actual app filename: %s.app" % app_file, LogLevel.VERBOSE, 4)
        facts["app_file"] = app_file

    # Determine the bundle identifier of the app. (Overwrites any previous
    # bundle_id, because the app itself is the most reliable source.)
    bundle_id = ""
    robo_print("Getting bundle identifier...", LogLevel.VERBOSE)
    if "CFBundleIdentifier" in info_plist:
        bundle_id = info_plist["CFBundleIdentifier"]
    else:
        robo_print("Strange, this app doesn't have a bundle "
                   "identifier.", LogLevel.ERROR)
    robo_print("Bundle idenfitier is: %s" % bundle_id, LogLevel.VERBOSE, 4)
    facts["bundle_id"] = bundle_id

    # Attempt to determine how to download this app.
    if "sparkle_feed" not in facts:
        sparkle_feed = ""
        download_format = ""
        robo_print("Checking for a Sparkle feed...", LogLevel.VERBOSE)
        if "SUFeedURL" in info_plist:
            sparkle_feed = info_plist["SUFeedURL"]
        elif "SUOriginalFeedURL" in info_plist:
            sparkle_feed = info_plist["SUOriginalFeedURL"]
        if sparkle_feed != "" and sparkle_feed != "NULL":
            facts = inspect_sparkle_feed_url(sparkle_feed, args, facts)
        else:
            robo_print("No Sparkle feed", LogLevel.VERBOSE, 4)

    if "is_from_app_store" not in facts:
        robo_print("Determining whether app was downloaded from the Mac App "
                   "Store...", LogLevel.VERBOSE)
        if os.path.exists("%s/Contents/_MASReceipt/receipt" % input_path):
            robo_print("App came from the App Store", LogLevel.VERBOSE, 4)
            facts["is_from_app_store"] = True
        else:
            robo_print("App did not come from the App Store", LogLevel.VERBOSE, 4)
            facts["is_from_app_store"] = False

    # Determine whether to use CFBundleShortVersionString or
    # CFBundleVersion for versioning.
    if "version_key" not in facts:
        version_key = ""
        robo_print("Looking for version key...", LogLevel.VERBOSE)
        if "CFBundleShortVersionString" in info_plist:
            if "CFBundleVersion" in info_plist:
                # Both keys exist, so we must decide with a cage match!
                try:
                    if StrictVersion(info_plist["CFBundleShortVersionString"]):
                        # CFBundleShortVersionString is strict. Use it.
                        version_key = "CFBundleShortVersionString"
                except ValueError:
                    # CFBundleShortVersionString is not strict.
                    try:
                        if StrictVersion(info_plist["CFBundleVersion"]):
                            # CFBundleVersion is strict. Use it.
                            version_key = "CFBundleVersion"
                    except ValueError:
                        # Neither are strict versions. Are they integers?
                        if info_plist["CFBundleShortVersionString"].isdigit():
                            version_key = "CFBundleShortVersionString"
                        elif info_plist["CFBundleVersion"].isdigit():
                            version_key = "CFBundleVersion"
                        else:
                            # CFBundleShortVersionString wins by default.
                            version_key = "CFBundleShortVersionString"
            else:
                version_key = "CFBundleShortVersionString"
        else:
            if "CFBundleVersion" in info_plist:
                version_key = "CFBundleVersion"
        if version_key != "":
            robo_print("Version key is: %s (%s)" %
                       (version_key, info_plist[version_key]), LogLevel.VERBOSE, 4)
            facts["version_key"] = version_key
        else:
            robo_print("Sorry, I can't determine which version key to use "
                       "for this app.", LogLevel.ERROR)

    # Determine path to the app's icon.
    if "icon_path" not in facts:
        icon_path = ""
        robo_print("Looking for app icon...", LogLevel.VERBOSE)
        if "CFBundleIconFile" in info_plist:
            icon_path = os.path.join(input_path, "Contents", "Resources", info_plist["CFBundleIconFile"])
        else:
            robo_print("Can't determine app icon.", LogLevel.WARNING)
        if icon_path != "":
            robo_print("App icon is: %s" % icon_path, LogLevel.VERBOSE, 4)
            facts["icon_path"] = icon_path

    # Attempt to get a description of the app from MacUpdate.com.
    if "description" not in facts:
        robo_print("Getting app description from MacUpdate...", LogLevel.VERBOSE)
        description = get_app_description(app_name)
        if description != "":
            robo_print("Description: %s" % description, LogLevel.VERBOSE, 4)
            facts["description"] = description

    # Attempt to determine code signing verification/requirements.
    if "codesign_status" not in facts:
        codesign_status = ""
        codesign_reqs = ""
        robo_print("Determining whether app is codesigned...", LogLevel.VERBOSE)
        cmd = "codesign --display -r- \"%s\"" % (input_path)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:
            codesign_status = "signed"
            # Determine code signing requirements.
            marker = "designated => "
            for line in out.split("\n"):
                if line.startswith(marker):
                    codesign_reqs = line[len(marker):]
        else:
            codesign_status = "unsigned"
        robo_print("Codesign status is: %s" % codesign_status, LogLevel.VERBOSE, 4)
        facts["codesign_status"] = codesign_status
        if codesign_reqs != "":
            robo_print("Codesign requirements are: %s" % codesign_reqs, LogLevel.VERBOSE, 4)
            facts["codesign_reqs"] = codesign_reqs

    # Attempt to determine name of developer and code signature version.
    # This overwrites existing developer names, because the app is canonical.
    if codesign_status != "unsigned":
        developer = ""
        codesign_version = ""
        robo_print("Determining application developer and codesign version...", LogLevel.VERBOSE)
        cmd = "codesign --display -r- --verbose=3 \"%s\"" % (input_path)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:
            dev_marker = "Authority=Developer ID Application: "
            vers_marker = "Sealed Resources version="
            # For some reason, the information we want is output to stderr.
            for line in err.split("\n"):
                if line.startswith(dev_marker):
                    if " (" in line:
                        line = line.split(" (")[0]
                    developer = line[len(dev_marker):]
                if line.startswith(vers_marker):
                    codesign_version = line[len(vers_marker):len(vers_marker) + 1]
        if developer != "":
            robo_print("Developer: %s" % developer, LogLevel.VERBOSE, 4)
            facts["developer"] = developer
        if codesign_version != "":
            robo_print("Codesign version: %s" % codesign_version, LogLevel.VERBOSE, 4)
            if codesign_version == "1":
                robo_print("This app uses an obsolete code signature.", LogLevel.WARNING)
                facts["codesign_status"] = "obsolete"

    return facts


def inspect_recipe(input_path, args, facts):
    """Process a recipe, gathering information useful for building other types
    of recipes.
    """

    # Read the recipe as a plist.
    robo_print("Validating recipe...", LogLevel.VERBOSE)
    try:
        input_recipe = FoundationPlist.readPlist(input_path)
        robo_print("Recipe is a valid plist", LogLevel.VERBOSE, 4)
    except Exception:
        robo_print("Could not parse recipe as a plist.", LogLevel.WARNING)

    # Run autopkg info on the recipe and save the output.
    cmd = "autopkg info \"%s\"" % input_path
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    if exitcode == 0:
        out = out.split("\n")
    else:
        robo_print("Could not run \"autopkg info\" on recipe.", LogLevel.WARNING)

    # Determine the name of the app.
    if "app_name" not in facts:
        app_name = ""
        robo_print("Getting name of app...", LogLevel.VERBOSE)
        if "Input" in input_recipe:
            if "NAME" in input_recipe["Input"]:
                app_name = input_recipe["Input"]["NAME"]
        if app_name != "":
            robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
            facts["app_name"] = app_name
            # If the app exists on disk, we can cheat by using it as input.
            if os.path.exists("/Applications/%s.app" % app_name):
                inspect_app("/Applications/%s.app" % app_name, args, facts)

    # Determine parent recipe, and get more facts from it.
    marker = "Parent recipe(s):"
    parent_recipe_path = ""
    robo_print("Looking for a parent recipe...", LogLevel.VERBOSE)
    for line in out:
        if marker in line:
            parent_recipe_path = line[len(marker):].lstrip()
    if parent_recipe_path != "":
        robo_print("Parent recipe is: %s" % parent_recipe_path, LogLevel.VERBOSE, 4)
        facts = inspect_recipe(parent_recipe_path, args, facts)
    else:
        robo_print("No parent recipe found", LogLevel.VERBOSE, 4)

    # Determine whether there's a Sparkle feed.
    if "sparkle_feed" not in facts:
        marker = "SPARKLE"
        robo_print("Looking for a Sparkle feed...", LogLevel.VERBOSE)
        for line in out:
            if marker in line:
                sparkle_feed = line.split("\"")[-2]
                facts = inspect_sparkle_feed_url(sparkle_feed, args, facts)

    # Determine whether there's a download URL.
    if "download_url" not in facts:
        marker = "DOWNLOAD_URL"
        robo_print("Looking for a direct download URL...", LogLevel.VERBOSE)
        for line in out:
            if marker in line:
                download_url = line[len(marker):].lstrip()
                facts = inspect_download_url(download_url, args, facts)

    # Get the download file format.
    if "download_format" not in facts:
        download_format = ""
        robo_print("Trying to determine download format...", LogLevel.VERBOSE)
        for test_format in all_supported_formats:
            cmd = "grep '.%s</string>' '%s'" % (test_format, input_path)
            exitcode, out, err = get_exitcode_stdout_stderr(cmd)
            if exitcode == 0:
                download_format = test_format
                break
        if download_format != "":
            robo_print("Download format (from recipe) is: %s" % download_format, LogLevel.VERBOSE, 4)
            facts["download_format"] = download_format

    # Run the recipe and inspect the resulting app.
    # robo_print("Running recipe to see what we get...", LogLevel.VERBOSE)
    # cmd = "autopkg run \"%s\"" % input_path
    # exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    # if exitcode == 0:
    #     pass

    return facts


def create_existing_recipe_list(app_name, recipes, args):
    """Use autopkg search results to build existing recipe list.

    Args:
        app_name: The name of the app for which we're searching for recipes.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.
    """

    # TODO(Elliot): Suggest users create GitHub API token to prevent limiting. (#29)

    # If --include-existing is specified, no need to search at all.
    if args.include_existing is True:
        return

    recipe_searches = []
    recipe_searches.append(app_name)

    app_name_no_space = "".join(app_name.split())
    if app_name_no_space != app_name:
        recipe_searches.append(app_name_no_space)

    app_name_no_symbol = re.sub(r'[^\w]', '', app_name)
    if app_name_no_symbol != app_name and app_name_no_symbol != app_name_no_space:
        recipe_searches.append(app_name_no_symbol)

    for this_search in recipe_searches:
        robo_print("Searching for existing AutoPkg recipes for \"%s\"..." % this_search, LogLevel.VERBOSE)
        if args.github_token is True:
            if not os.path.exists(os.path.expanduser("~/.autopkg_gh_token")):
                robo_print("I couldn't find a GitHub token to use.", LogLevel.WARNING)
                cmd = "/usr/local/bin/autopkg search --path-only \"%s\"" % this_search
            else:
                # TODO(Elliot): Learn how to use the GitHub token. (#18) https://github.com/autopkg/autopkg/blob/680c75855f00b588e6dd50fb431bed5d5fd41d9c/Code/autopkglib/github/__init__.py#L31
                robo_print("I found a GitHub token, but I'm still learning how to use it.", LogLevel.WARNING)
                cmd = "/usr/local/bin/autopkg search --path-only --use-token \"%s\"" % this_search
        else:
            cmd = "/usr/local/bin/autopkg search --path-only \"%s\"" % this_search
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        out = out.split("\n")
        if exitcode == 0:
            # TODO(Elliot): There's probably a more efficient way to do this.
            # For each recipe type, see if it exists in the search results.
            is_existing = False
            for recipe in recipes:
                recipe_name = "%s.%s.recipe" % (this_search, recipe["type"])
                for line in out:
                    if line.lower().startswith(recipe_name.lower()):
                        # Set to False by default. If found, set to True.
                        recipe["existing"] = True
                        robo_print("Found existing %s" % recipe_name, LogLevel.VERBOSE, 4)
                        is_existing = True
                        break
            if not is_existing:
                robo_print("No results", LogLevel.VERBOSE, 4)
        else:
            robo_print(err, LogLevel.ERROR)


def create_buildable_recipe_list(app_name, recipes, args, facts):
    """Add any preferred recipe types that don't already exist to the buildable
    list.

    Args:
        app_name: The name of the app for which we're searching for recipes.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.
        facts: A continually-updated dictionary containing all the information
            we know so far about the app associated with the input path.
    """

    # Determine which recipes are buildable based on "preferred" preference
    # values and the --include-existing argument.
    for recipe in recipes:
        if args.include_existing is False:
            if recipe["preferred"] is True and recipe["existing"] is False:
                recipe["buildable"] = True
        else:
            if recipe["preferred"] is True:
                recipe["buildable"] = True


def debug_dump(items):
    """Dump all the variables we know about to output.

    Args:
        items: A dict of dicts of all the things to dump to output.
    """
    for key, value in items.iteritems():
        print "%s\n%s:\n\n%s\n%s" % (BColors.DEBUG, key.upper(),
                                     pprint.pformat(value), BColors.ENDC)


def congratulate(prefs):
    """Display a friendly congratulatory message upon creating recipes.

    Args:
        prefs: A dictionary containing a key/value pair for each preference.
    """
    congrats_msg = (
        "Amazing.",
        "Easy peasy.",
        "Fantastic.",
        "Good on ya!",
        "Imagine all the typing you saved.",
        "Isn't meta-automation great?",
        "(Yep, it's pretty fun for me too.)",
        "Pretty cool, right?",
        "Round of applause for you!",
        "Terrific job!",
        "Thanks!",
        "That's awesome!",
        "Want to do another?",
        "Well done!",
        "You rock star, you."
    )
    if prefs["RecipeCreateCount"] == 1:
        robo_print("\nYou've created your first recipe with Recipe "
                   "Robot. Congratulations!\n")
    elif prefs["RecipeCreateCount"] > 1:
        robo_print("\nYou've now created %s recipes with Recipe Robot. "
                   "%s\n" % (prefs["RecipeCreateCount"],
                             random.choice(congrats_msg)))


def main():
    """Make the magic happen."""

    try:
        # Reset terminal colors, in case the last run aborted uncleanly.
        recipe_robot_lib.tools.reset_term_colors()

        # Print welcome and version number.
        print_welcome_text()

        # Parse command line arguments.
        argparser = build_argument_parser()
        args = argparser.parse_args()

        # If no input path nor --config arg was specified, print help and exit.
        if not args.input_path and not args.config:
            argparser.print_help()
            sys.exit(0)

        # If --include-existing was specified, print a warning.
        if args.include_existing is True:
            robo_print("Will build recipes even if they already exist in "
                       "\"autopkg search\" results. Please don't upload "
                       "duplicate recipes.", LogLevel.WARNING)

        # If --verbose was specified, set verbose mode to True.
        if args.verbose is True or OutputMode.verbose_mode is True:
            OutputMode.set_verbose_mode(True)

        # Create the master recipe information list.
        recipes = init_recipes()

        # Read or create the user preferences.
        prefs = {}
        prefs = init_prefs(prefs, recipes, args)

        # If --config was specified without an input path, stop here.
        if not args.input_path:
            sys.exit(0)
        # Otherwise, retrieve the input path.
        input_path = args.input_path

        # Strip trailing slash, but only if input_path is not a URL.
        if "http" not in input_path:
            input_path = input_path.rstrip("/ ")

        robo_print("Processing %s ..." % input_path)

        # Collect facts from the input path, based on the type of path given.
        facts = {}
        process_input_path(input_path, args, facts)

        # Look up existing recipes. (App name is required to proceed.)
        if "app_name" in facts:
            create_existing_recipe_list(facts["app_name"], recipes, args)
        else:
            robo_print("I wasn't able to determine the name of this app, "
                       "so I can't make any recipes.", LogLevel.ERROR)

        # Determine which recipes we can build.
        create_buildable_recipe_list(facts["app_name"], recipes, args, facts)

        # Create recipes for the recipe types that were selected above.
        recipe_robot_lib.generate_recipes(facts, prefs, recipes)

        # If debug is on, print all the things.
        if OutputMode.debug_mode is True:
            debug_dump({
                "Command line arguments": args,
                "Supported file formats": all_supported_formats,
                "Preferences for this session": prefs,
                "Recipe information": recipes,
                "Facts we have collected": facts
            })

        # Pat on the back!
        congratulate(prefs)

        # Clean up cache folder.
        if os.path.exists(cache_dir) and args.keep_cache is not True:
            shutil.rmtree(cache_dir)

    # If killed, make sure to reset the terminal color with our dying breath.
    except (KeyboardInterrupt, SystemExit):
        recipe_robot_lib.tools.reset_term_colors()


if __name__ == '__main__':
    main()
