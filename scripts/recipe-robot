#!/usr/bin/python
# This Python file uses the following encoding: utf-8

# Recipe Robot
# Copyright 2015 Elliot Jordan, Shea G. Craig
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


"""
recipe-robot

Easily and automatically create AutoPkg recipes.

usage: recipe-robot.py [-h] [-v] [-o OUTPUT_DIR] [-t RECIPE_TYPES]
                       [--include-existing] [--config]
                       input_path

positional arguments:
  input_path            Path to a recipe or app from which to derive AutoPkg
                        recipes.

optional arguments:
  -h, --help            show this help message and exit
  -v, --verbose         Generate additional output about the process.
  -o OUTPUT_DIR, --output-dir OUTPUT_DIR
                        Path to a folder you'd like to save your generated
                        recipes in.
  -t RECIPE_TYPES, --recipe-types RECIPE_TYPES
                        The types of recipe you'd like to generate.
  --include-existing    Offer to generate recipes even if one already exists
                        on GitHub.
  --config              Adjust Recipe Robot preferences prior to generating
                        recipes.
"""


import argparse
from distutils.version import StrictVersion
import json
import os
#TODO: Remove for release
import pdb
import pprint
import random
import re
import shutil
import sys
from urllib2 import urlopen, build_opener
from urlparse import urlparse
from xml.etree.ElementTree import parse, ParseError

import recipe_robot_lib
from recipe_robot_lib.tools import (create_dest_dirs,
                                    get_exitcode_stdout_stderr, robo_print,
                                    LogLevel, OutputMode, print_welcome_text,
                                    __version__)
# TODO(Elliot): Can we use the one at /Library/AutoPkg/FoundationPlist instead?
# Or not use it at all (i.e. use the preferences system correctly).
try:
    from recipe_robot_lib import FoundationPlist
except:
    print '[WARNING] importing plistlib as FoundationPlist'
    import plistlib as FoundationPlist


# Global variables.
prefs_file = os.path.expanduser(
    "~/Library/Preferences/com.elliotjordan.recipe-robot.plist")
cache_dir = os.path.expanduser("~/Library/Caches/Recipe Robot")

# Build the list of download formats we know about.
supported_image_formats = ("dmg", "iso")  # downloading iso unlikely
supported_archive_formats = ("zip", "tar.gz", "gzip", "tar.bz2", "tbz", "tgz")
supported_install_formats = ("pkg", "mpkg")  # downloading mpkg unlikely
all_supported_formats = (supported_image_formats + supported_archive_formats +
                         supported_install_formats)


def build_argument_parser():
    """Build and return the argument parser for Recipe Robot.

    Returns:
        Parser object.
    """

    parser = argparse.ArgumentParser(
        description="Easily and automatically create AutoPkg recipes.")
    parser.add_argument(
        "input_path",
        help="Path from which to derive AutoPkg recipes. This can be one of "
             "the following: existing app, existing AutoPkg recipe, Sparkle "
             "feed, GitHub or SourceForge URL, or direct download URL.")
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Generate additional output about the process.")
    parser.add_argument(
        "-o", "--output-dir",
        action="store",
        help="Path to a folder you'd like to save your generated recipes in.")
    parser.add_argument(
        "-t", "--recipe-types",
        action="store",
        help="The types of recipe you'd like to generate.")
    parser.add_argument(
        "--include-existing",
        action="store_true",
        help="Offer to generate recipes even if one already exists on GitHub.")
    parser.add_argument(
        "--config",
        action="store_true",
        help="Adjust Recipe Robot preferences prior to generating recipes.")
    return parser


def init_recipes():
    """Store information related to each supported AutoPkg recipe type.

    Returns:
        A tuple of dicts that describe all the AutoPkg recipe types we know about.
    """

    recipes = ({
        "type": "download",
        "description": "Downloads an app in whatever format the developer "
                       "provides."
        }, {
            "type": "munki",
            "description": "Imports into your Munki repository."
        }, {
            "type": "pkg",
            "description": "Creates a standard pkg installer file."
        }, {
            "type": "install",
            "description": "Installs the app on the computer running AutoPkg."
        }, {
            "type": "jss",
            "description": "Imports into your Casper JSS and creates "
                           "necessary groups, policies, etc."
        }, {
            "type": "absolute",
            "description": "Imports into your Absolute Manage server."
        }, {
            "type": "sccm",
            "description": "Creates a cmmac package for deploying via "
                           "Microsoft SCCM."
        }, {
            "type": "ds",
            "description": "Imports into your DeployStudio Packages folder."
        })

    # Set default values for all recipe types.
    for recipe in recipes:
        recipe["preferred"] = True
        recipe["existing"] = False
        recipe["buildable"] = False

    return recipes


def init_prefs(prefs, recipes, args):
    """Read Recipe Robot preferences in the following priority order:
        0. If --config argument is specified, ignore prefs and rebuild.
        3. If preferences plist doesn't exist, rebuild.
        4. If preferences plist does exist, use it.

    Args:
        prefs: A dictionary containing a key/value pair for each preference.
            When this function is called for the first time, the prefs dict
            is typically empty.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.

    Returns:
        prefs: A fully populated preference dictionary.
    """

    prefs = {}
    global prefs_file

    # If prefs file exists, try to read from it.
    if os.path.isfile(prefs_file):

        # Open the file.
        try:
            prefs = FoundationPlist.readPlist(prefs_file)
        except Exception:
            robo_print("There was a problem opening the prefs file. Building "
                       "new preferences.", LogLevel.WARNING)
            prefs = build_prefs(prefs, recipes)

        for recipe in recipes:
            # Load preferred recipe types.
            if recipe["type"] in prefs["RecipeTypes"]:
                recipe["preferred"] = True
            else:
                recipe["preferred"] = False

        if args.config is True:
            robo_print("Showing configuration options...")
            prefs = build_prefs(prefs, recipes)

        # This seems to be necessary in order to avoid an error when reading
        # the plist back during subsequent runs.
        prefs["RecipeCreateCount"] = int(prefs["RecipeCreateCount"])

    else:
        robo_print("No prefs file found. Building new preferences...",
                   LogLevel.WARNING)
        prefs = build_prefs(prefs, recipes)

    # Record last version number.
    prefs["LastRecipeRobotVersion"] = __version__

    # Save preferences to disk for next time.
    FoundationPlist.writePlist(prefs, prefs_file)

    return prefs


def build_prefs(prefs, recipes):
    """Prompt user for preferences, then save them back to the plist.

    Args:
        prefs: The preference dictionary, passed from init_prefs().
        recipes: The list of known recipe types, created by init_recipes().

    Returns:
        prefs: The preference dictionary, newly populated from user input.
    """

    # Start recipe count at zero, if no value already exists.
    if "RecipeCreateCount" not in prefs:
        prefs["RecipeCreateCount"] = int(0)

    # Prompt for and save recipe identifier prefix.
    prefs["RecipeIdentifierPrefix"] = "com.github.homebysix"
    robo_print("\nRecipe identifier prefix")
    robo_print("This is your default identifier, in reverse-domain notation.\n")
    choice = raw_input(
        "[%s]: " % prefs["RecipeIdentifierPrefix"])
    if choice != "":
        prefs["RecipeIdentifierPrefix"] = str(choice).rstrip(". ")

    # Prompt for recipe creation location.
    prefs["RecipeCreateLocation"] = "~/Library/AutoPkg/RecipeOverrides"
    robo_print("\nLocation to save new recipes")
    robo_print("This is where on disk your newly created recipes will be saved.\n")
    choice = raw_input(
        "[%s]: " % prefs["RecipeCreateLocation"])
    if choice != "":
        prefs["RecipeCreateLocation"] = str(choice).rstrip("/ ")

    # Prompt to set recipe types on/off as desired.
    prefs["RecipeTypes"] = []
    robo_print("\nPreferred recipe types")
    robo_print("Choose which recipe types will be offered to you by default.\n")
    # TODO(Elliot): Make this interactive while retaining scrollback.
    # Maybe with curses module?
    while True:
        i = 0
        for recipe in recipes:
            if recipe["preferred"] is False:
                indicator = " "
            else:
                indicator = "*"
            robo_print("[%s] %s. %s - %s" %
                       (indicator, i, recipe["type"], recipe["description"]),
                       indent=2)
            i += 1
        robo_print("A. Enable all recipe types.", indent=6)
        robo_print("D. Disable all recipe types.", indent=6)
        robo_print("Q. Quit without saving changes.", indent=6)
        robo_print("S. Save changes and proceed.", indent=6)
        choice = raw_input(
            "\nType a number to toggle the corresponding recipe "
            "type between ON [*] and OFF [ ].\nWhen you're satisfied "
            "with your choices, type an \"S\" to save and proceed: ")
        if choice.upper() == "S":
            break
        elif choice.upper() == "A":
            for recipe in recipes:
                recipe["preferred"] = True
        elif choice.upper() == "D":
            for recipe in recipes:
                recipe["preferred"] = False
        elif choice.upper() == "Q":
            sys.exit(0)
        else:
            try:
                if recipes[int(choice)]["preferred"] is False:
                    recipes[int(choice)]["preferred"] = True
                else:
                    recipes[int(choice)]["preferred"] = False
            except Exception:
                robo_print("%s is not a valid option. Please try "
                           "again.\n" % choice, LogLevel.WARNING)

    # Set "preferred" status of each recipe type according to preferences.
    for recipe in recipes:
        if recipe["preferred"] is True:
            prefs["RecipeTypes"].append(recipe["type"])

            if recipe["type"] == "ds":
                prefs["DSPackagesPath"] = "/Shared/DeployStudio/Packages"
                robo_print("\nLocation of your DeployStudio packages:")
                robo_print("This where packages will be copied in order to "
                                  "appear in DeployStudio.\n")
                choice = raw_input(
                    "[%s]: " % prefs["DSPackagesPath"])
                if choice != "":
                    prefs["DSPackagesPath"] = str(choice).rstrip("/ ")

    return prefs


def process_input_path(input_path, args, facts):
    """Determine which functions to call based on the type of input path.

    Args:
        input_path: The path or URL that Recipe Robot was asked to use to
            create recipes.
        args: The command line arguments.
        facts: A continually-updated dictionary containing all the information
            we know so far about the app associated with the input path.
    """

    # Keep track of the inspections we perform, to make sure we don't loop.
    facts["inspections"] = []

    if input_path.startswith("http"):
        if input_path.endswith(".xml") or input_path.endswith(".php"):
            robo_print("Input path looks like a Sparkle feed.",
                       LogLevel.VERBOSE)
            facts = inspect_sparkle_feed_url(input_path, args, facts)
        elif ("github.com" in input_path or
              "githubusercontent.com" in input_path):
            robo_print("Input path looks like a GitHub URL.", LogLevel.VERBOSE)
            facts = inspect_github_url(input_path, args, facts)
        elif "sourceforge.net" in input_path:
            robo_print("Input path looks like a SourceForge URL.",
                       LogLevel.VERBOSE)
            facts = inspect_sourceforge_url(input_path, args, facts)
        elif "bitbucket.org" in input_path:
            robo_print("Input path looks like a BitBucket URL.",
                       LogLevel.VERBOSE)
            facts = inspect_bitbucket_url(input_path, args, facts)
        else:
            robo_print("Input path looks like a download URL.",
                       LogLevel.VERBOSE)
            facts = inspect_download_url(input_path, args, facts)
    elif input_path.startswith("ftp"):
        robo_print("Input path looks like a download URL.", LogLevel.VERBOSE)
        facts = inspect_download_url(input_path, args, facts)
    elif os.path.exists(input_path):
        if input_path.endswith(".app"):
            robo_print("Input path looks like an app.", LogLevel.VERBOSE)
            facts = inspect_app(input_path, args, facts)
        elif input_path.endswith(".recipe"):
            robo_print("Input path looks like a recipe.", LogLevel.VERBOSE)
            facts = inspect_recipe(input_path, args, facts)
        else:
            robo_print("I haven't been trained on how to handle this "
                       "input path:\n    %s" % input_path, LogLevel.ERROR)
            # TODO(Elliot): Handle zipped pkgs. Example:
            # http://www.busymac.com/download/BusyCal.zip
    else:
        robo_print("Input path does not exist. Please try again with a "
                   "valid input path.", LogLevel.ERROR)


def get_app_description(app_name):
    """Use an app's name to generate a description from MacUpdate.com.

    Args:
        app_name: The name of the app that we need to describe.

    Returns:
        description: A string containing a description of the app.
    """

    # Start with an empty string. (If it remains empty, the parent function
    # will know that no description was available.)
    description = ""

    # This is the HTML immediately preceding the description text on the
    # MacUpdate search results page.
    description_marker = "-shortdescrip\">"

    cmd = "curl -s \"http://www.macupdate.com/find/mac/%s\"" % app_name
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)

    # For each line in the resulting text, look for the description marker.
    html = out.split("\n")
    if exitcode == 0:
        for line in html:
            if description_marker in line:
                # Trim the HTML from the beginning of the line.
                start = line.find(description_marker) + len(description_marker)
                # Trim the HTML from the end of the line.
                description = line[start:].rstrip("</span>")
                # If we found a description, no need to process further lines.
                break
    else:
        robo_print("Error occurred while getting description from "
                   "MacUpdate: %s" % err, LogLevel.WARNING)

    return description


def inspect_github_url(input_path, args, facts):
    """Process a GitHub URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this GitHub URL yet.
    if "github_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("github_url")

    # Grab the GitHub repo path.
    github_repo = ""
    robo_print("Getting GitHub repo...", LogLevel.VERBOSE)
    # TODO(Elliot): Match all these examples:
    # [x] https://github.com/jbtule/cdto/releases/download/2_6_0/cdto_2_6.zip
    # [x] https://github.com/lindegroup/autopkgr
    # [x] https://raw.githubusercontent.com/macmule/AutoCasperNBI/master/README.md
    # [ ] https://api.github.com/repos/macmule/AutoCasperNBI
    # [ ] https://hjuutilainen.github.io/munkiadmin/
    r_obj = re.search(r"^https?://(?:[\w]+\.)?github(?:.+)?\.com/([\w-]+/[\w-]+)(?:.+)?$", input_path)
    if r_obj is not None:
        github_repo = r_obj.group(1)
    if github_repo != "":
        robo_print("GitHub repo is: %s" % github_repo, LogLevel.VERBOSE, 4)
        facts["github_repo"] = github_repo

        # TODO(Elliot): How can we use GitHub tokens to prevent rate limiting?

        # Use GitHub API to obtain information about the repo and releases.
        # TODO(Shea): From here to line 490 can probably be simplified.
        repo_api_url = "https://api.github.com/repos/%s" % github_repo
        releases_api_url = "https://api.github.com/repos/%s/releases/latest" % github_repo
        user_api_url = "https://api.github.com/users/%s" % github_repo.split("/")[0]

        # Download the repo information from the GitHub API.
        try:
            raw_json_repo = urlopen(repo_api_url).read()
        except Exception as err:
            # TODO(Elliot): Differentiate 404 not found vs 403 forbidden.
            robo_print("Error occurred while getting repo information from "
                       "the GitHub API. If you've been creating a lot of "
                       "recipes quickly, you may have hit the rate limit. "
                       "Give it a few minutes, then try "
                       "again. (%s)" % err, LogLevel.WARNING)
            return facts

        # Download the release information from the GitHub API.
        try:
            raw_json_release = urlopen(releases_api_url).read()
        except Exception as err:
            # TODO(Elliot): Differentiate 404 not found vs 403 forbidden.
            robo_print("Error occurred while getting release information from "
                       "the GitHub API. If you've been creating a lot of "
                       "recipes quickly, you may have hit the rate limit. "
                       "Give it a few minutes, then try "
                       "again. (%s)" % err, LogLevel.WARNING)
            return facts

        # Download the owner/developer information from the GitHub API.
        try:
            raw_json_user = urlopen(user_api_url).read()
        except Exception as err:
            # TODO(Elliot): Differentiate 404 not found vs 403 forbidden.
            robo_print("Error occurred while getting owner information from "
                       "the GitHub API. If you've been creating a lot of "
                       "recipes quickly, you may have hit the rate limit. "
                       "Give it a few minutes, then try "
                       "again. (%s)" % err, LogLevel.WARNING)
            return facts

        # Parse the downloaded JSON.
        parsed_repo = json.loads(raw_json_repo)
        parsed_release = json.loads(raw_json_release)
        parsed_user = json.loads(raw_json_user)

        # Get app name.
        if "app_name" not in facts:
            app_name = ""
            robo_print("Getting app name...", LogLevel.VERBOSE)
            if "name" in parsed_repo:
                if parsed_repo["name"] != "":
                    app_name = parsed_repo["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Get app description.
        if "description" not in facts:
            description = ""
            robo_print("Getting GitHub description...", LogLevel.VERBOSE)
            if "description" in parsed_repo:
                if parsed_repo["description"] != "":
                    description = parsed_repo["description"]
            if description != "":
                robo_print("GitHub description is: %s" % description,
                           LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("Could not detect GitHub description.",
                           LogLevel.WARNING)

        # Get download format of latest release.
        if "download_format" not in facts or "download_url" not in facts:
            download_format = ""
            download_url = ""
            robo_print("Getting information from latest GitHub release...",
                       LogLevel.VERBOSE)
            if "assets" in parsed_release:
                for asset in parsed_release["assets"]:
                    for this_format in all_supported_formats:
                        if asset["browser_download_url"].endswith(this_format):
                            download_format = this_format
                            download_url = asset["browser_download_url"]
                            break
            if download_format != "":
                robo_print("GitHub release download format "
                           "is: %s" % download_format,
                           LogLevel.VERBOSE, 4)
                facts["download_format"] = download_format
            else:
                robo_print("Could not detect GitHub release download format.",
                           LogLevel.WARNING)
            if download_url != "":
                robo_print("GitHub release download URL "
                           "is: %s" % download_url, LogLevel.VERBOSE, 4)
                facts["download_url"] = download_url
                inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect GitHub release download URL.",
                           LogLevel.WARNING)

        # Get the developer's name from GitHub.
        if "developer" not in facts:
            developer = ""
            robo_print("Getting developer name from GitHub...",
                       LogLevel.VERBOSE)
            if "name" in parsed_user:
                developer = parsed_user["name"]
            if developer != "":
                robo_print("GitHub developer "
                           "is: %s" % developer, LogLevel.VERBOSE, 4)
                facts["developer"] = developer
            else:
                robo_print("Could not detect GitHub developer.",
                           LogLevel.WARNING)

        # Warn user if the GitHub project is private.
        if "private" in parsed_repo:
            if parsed_repo["private"] is True:
                robo_print("This GitHub project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

        # Warn user if the GitHub project is a fork.
        if "private" in parsed_repo:
            if parsed_repo["fork"] is True:
                robo_print("This GitHub project is a fork. You may want to "
                           "try again with the original repo URL instead.", LogLevel.WARNING)
    else:
        robo_print("Could not detect GitHub repo.", LogLevel.WARNING)

    return facts


def inspect_sourceforge_url(input_path, args, facts):
    """Process a SourceForge URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this SourceForge URL yet.
    if "sourceforge_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("sourceforge_url")

    # Determine the name of the SourceForge project.
    proj_name = ""
    # TODO(Elliot): Is it better to do this with re.search()?
    if  "/projects/" in input_path:
        # Example: http://sourceforge.net/projects/adium/?source=recommended
        # Example: http://sourceforge.net/projects/grandperspectiv
        # Example: http://sourceforge.net/projects/grandperspectiv/
        marker = "/projects/"
        proj_str = input_path[input_path.find(marker) + len(marker):]
        if proj_str.find("/") > 0:
            proj_name = proj_str[:proj_str.find("/")]
        else:
            proj_name = proj_str
    elif "/p/" in input_path:
        # Example: http://sourceforge.net/p/grandperspectiv/wiki/Home/
        marker = "/p/"
        proj_str = input_path[input_path.find(marker) + len(marker):]
        if proj_str.find("/") > 0:
            proj_name = proj_str[:proj_str.find("/")]
        else:
            proj_name = proj_str
    elif ".sourceforge.net" in input_path:
        # Example: http://grandperspectiv.sourceforge.net/
        # Example: http://grandperspectiv.sourceforge.net/screenshots.html
        marker = ".sourceforge.net"
        proj_str = input_path.lstrip("http://")
        proj_name = proj_str[:proj_str.find(marker)]
    else:
        robo_print("Unable to parse SourceForge URL.", LogLevel.WARNING)
    if proj_name != "":

        # Use SourceForge API to obtain project information.
        project_api_url = "https://sourceforge.net/rest/p/" + proj_name
        raw_json = urlopen(project_api_url).read()
        parsed_json = json.loads(raw_json)

        # Get app name.
        if "app_name" not in facts:
            if "shortname" in parsed_json or "name" in parsed_json:
                # Record the shortname, if shortname isn't blank.
                if parsed_json["shortname"] != "":
                    app_name = parsed_json["shortname"]
                # Overwrite the shortname with name, if name isn't blank.
                if parsed_json["name"] != "":
                    app_name = parsed_json["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Determine project ID.
        proj_id = ""
        robo_print("Getting SourceForge project ID...", LogLevel.VERBOSE)
        for this_dict in parsed_json["tools"]:
            if "sourceforge_group_id" in this_dict:
                proj_id = this_dict["sourceforge_group_id"]
        if proj_id != "":
            robo_print("SourceForge project ID is: %s" % proj_id, LogLevel.VERBOSE, 4)
            facts["sourceforge_proj_id"] = proj_id
        else:
            robo_print("Could not detect SourceForge project ID.", LogLevel.WARNING)

        # Get project description.
        if "description" not in facts:
            description = ""
            robo_print("Getting SourceForge description...", LogLevel.VERBOSE)
            if "summary" in parsed_json:
                if parsed_json["summary"] != "":
                    description = parsed_json["summary"]
                elif parsed_json["short_description"] != "":
                    description = parsed_json["short_description"]
            if description != "":
                robo_print("SourceForge description is: %s" % description, LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("Could not detect SourceForge description.", LogLevel.WARNING)

        # Get download format of latest release.
        if "download_url" not in facts:

            # Download the RSS feed and parse it.
            # Example: http://sourceforge.net/projects/grandperspectiv/rss
            # Example: http://sourceforge.net/projects/cord/rss
            # TODO(Elliot): Per SourceForge TOS we should limit RSS
            # requests to one hit per 30 minute period per feed.
            files_rss = "http://sourceforge.net/projects/%s/rss" % proj_name
            try:
                raw_xml = urlopen(files_rss)
            except Exception as err:
                robo_print("Error occured while inspecting SourceForge RSS "
                           "feed: %s" % err, LogLevel.WARNING)
            doc = parse(raw_xml)

            # Get the latest download URL.
            download_url = ""
            robo_print("Determining download URL from SourceForge RSS feed...", LogLevel.VERBOSE)
            for item in doc.iterfind('channel/item'):
                # TODO(Elliot): The extra-info tag is not a reliable indicator
                # of which item should actually be downloaded.
                search = "{https://sourceforge.net/api/files.rdf#}extra-info"
                if item.find(search).text.startswith("data"):
                    download_url = item.find("link").text.rstrip("/download")
                    break
            if download_url != "":
                facts = inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect SourceForge latest release download_url.", LogLevel.WARNING)

        # Warn user if the SourceForge project is private.
        if "private" in parsed_json:
            if parsed_json["private"] is True:
                robo_print("This SourceForge project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

        # TODO(Elliot): Can we make use of parsed_json["icon"]?
        # Example: https://sourceforge.net/p/adium/icon

    else:
        robo_print("Could not detect SourceForge project name.", LogLevel.WARNING)

    return facts


def inspect_bitbucket_url(input_path, args, facts):
    """Process a BitBucket URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this BitBucket URL yet.
    if "bitbucket_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("bitbucket_url")

    # Grab the BitBucket repo path.
    bitbucket_repo = ""
    robo_print("Getting BitBucket repo...", LogLevel.VERBOSE)
    r_obj = re.search(r"(?<=https://bitbucket\.org/)[\w-]+/[\w-]+", input_path)
    if r_obj is not None:
        bitbucket_repo = r_obj.group(0)
    if bitbucket_repo != "":
        robo_print("BitBucket repo is: %s" % bitbucket_repo, LogLevel.VERBOSE, 4)
        facts["bitbucket_repo"] = bitbucket_repo

        # Use GitHub API to obtain information about the repo and releases.
        repo_api_url = "https://api.bitbucket.org/2.0/repositories/%s" % bitbucket_repo
        releases_api_url = "https://api.bitbucket.org/2.0/repositories/%s/downloads" % bitbucket_repo
        try:
            raw_json_repo = urlopen(repo_api_url).read()
            parsed_repo = json.loads(raw_json_repo)
            raw_json_release = urlopen(releases_api_url).read()
            parsed_release = json.loads(raw_json_release)
        except Exception as err:
            robo_print("Error occurred while talking to BitBucket. (%s)" % err, LogLevel.WARNING)
            return facts

        # Get app name.
        if "app_name" not in facts:
            app_name = ""
            robo_print("Getting app name...", LogLevel.VERBOSE)
            if "name" in parsed_repo:
                if parsed_repo["name"] != "":
                    app_name = parsed_repo["name"]
            if app_name != "":
                robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
                facts["app_name"] = app_name

        # Get full name of owner.
        developer = ""
        if "developer" not in facts:
            developer = parsed_repo["owner"]["display_name"]
        if developer != "":
            robo_print("BitBucket owner full name "
                       "is: %s" % developer, LogLevel.VERBOSE, 4)
            facts["developer"] = developer

        # Get app description.
        if "description" not in facts:
            description = ""
            robo_print("Getting BitBucket description...", LogLevel.VERBOSE)
            if "description" in parsed_repo:
                if parsed_repo["description"] != "":
                    description = parsed_repo["description"]
            if description != "":
                robo_print("BitBucket description is: %s" % description, LogLevel.VERBOSE, 4)
                facts["description"] = description
            else:
                robo_print("Could not detect BitBucket description.", LogLevel.WARNING)

        # Get download format of latest release.
        if "download_format" not in facts or "download_url" not in facts:
            download_format = ""
            download_url = ""
            robo_print("Getting information from latest BitBucket release...", LogLevel.VERBOSE)
            if "values" in parsed_release:
                for asset in parsed_release["values"]:
                    for this_format in all_supported_formats:
                        if asset["links"]["self"]["href"].endswith(this_format):
                            download_format = this_format
                            download_url = asset["links"]["self"]["href"]
                            break
            if download_format != "":
                robo_print("BitBucket release download format "
                           "is: %s" % download_format, LogLevel.VERBOSE, 4)
                facts["download_format"] = download_format
            else:
                robo_print("Could not detect BitBucket release download format.", LogLevel.WARNING)
            if download_url != "":
                robo_print("BitBucket release download URL "
                           "is: %s" % download_url, LogLevel.VERBOSE, 4)
                facts["download_url"] = download_url
                inspect_download_url(download_url, args, facts)
            else:
                robo_print("Could not detect BitBucket release download URL.", LogLevel.WARNING)

        # Warn user if the BitBucket project is private.
        if "is_private" in parsed_repo:
            if parsed_repo["is_private"] is True:
                robo_print("This BitBucket project is marked \"private\" "
                           "and recipes you generate may not work for others.", LogLevel.WARNING)

    else:
        robo_print("Could not detect BitBucket repo.", LogLevel.WARNING)

    return facts


def inspect_sparkle_feed_url(input_path, args, facts):
    """Process a Sparkle feed URL, gathering required information to create a
    recipe.
    """

    # Only proceed if we haven't inspected this Sparkle feed yet.
    if "sparkle_feed_url" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("sparkle_feed_url")

    # Save the Sparkle feed URL to the dictionary of facts.
    robo_print("Sparkle feed is: %s" % input_path, LogLevel.VERBOSE, 4)
    facts["sparkle_feed"] = input_path

    # Download the Sparkle feed and parse it.
    try:
        raw_xml = urlopen(input_path)
    except Exception as err:
        # Try again, this time with a user-agent.
        try:
            opener = build_opener()
            opener.addheaders = [('User-agent', 'Mozilla/5.0')]
            raw_xml = opener.open(input_path)
            robo_print("I had to use a different user-agent in order to "
                       "read this Sparkle feed. If you run the recipes and "
                       "get a \"Can't open URL\" error, it means AutoPkg "
                       "encountered the same problem.", LogLevel.WARNING)
            facts["user-agent"] = "Mozilla/5.0"
        except Exception as err:
            robo_print("Error occured while downloading Sparkle feed (%s)" % err, LogLevel.WARNING)
            # Remove Sparkle feed if it's not usable.
            facts.pop("sparkle_feed", None)
            return facts

    try:
        doc = parse(raw_xml)
    except ParseError as err:
        robo_print("Error occured while parsing Sparkle feed (%s)" % err, LogLevel.WARNING)
        return facts

    # Get the latest download URL.
    download_url = ""
    robo_print("Determining download URL from Sparkle feed...", LogLevel.VERBOSE)
    for item in doc.iterfind('channel/item/enclosure'):
        download_url = item.attrib["url"]
        break  # should stop after the most recent (first) enclosure item
        # TODO(Elliot): Not all Sparkle feeds list the most recent item first.
        # Example: http://www.marinersoftware.com/sparkle/MacGourmet4/macgourmet4.xml
    if download_url != "":
        facts = inspect_download_url(download_url, args, facts)

    # If Sparkle feed is hosted on GitHub or SourceForge, we can gather more
    # information.
    if "github.com" in input_path or "githubusercontent.com" in input_path:
        if "github_repo" not in facts:
            facts = inspect_github_url(input_path, args, facts)
    if "sourceforge.net" in input_path:
        if "sourceforge_id" not in facts:
            facts = inspect_sourceforge_url(input_path, args, facts)

    return facts


def inspect_download_url(input_path, args, facts):
    """Process a direct download URL, gathering required information to
    create a recipe.
    """

    # We never skip download URL inspection, even if we've already inspected
    # a download URL during this run. This handles rare situations in which
    # the download URL is in a different format than the Sparkle download.
    # Example: http://rdio0-a.akamaihd.net/media/static/desktop/mac/Rdio.dmg

    # Save the download URL to the dictionary of facts.
    robo_print("Download URL is: %s" % input_path, LogLevel.VERBOSE, 4)
    facts["download_url"] = input_path

    # Get the filename from the URL.
    # Example: https://www.dropbox.com/s/b0hk0i2n386824c/IconGrabber.dmg?dl=1
    # Should produce: IconGrabber.dmg
    robo_print("Getting download filename...", LogLevel.VERBOSE)
    parsed_url = urlparse(input_path)
    filename = parsed_url.path.split("/")[-1]
    if filename != "":
        robo_print("Download filename is: %s" % filename, LogLevel.VERBOSE, 4)
        r_obj = re.search(r"[\d]+\.[\w]+$", input_path)
        if r_obj is not None and ("sparkle_feed" not in facts and
                                  "github_repo" not in facts and
                                  "sourceforge_id" not in facts and
                                  "bitbucket_repo" not in facts):
            robo_print("Careful, this might be a version-specific URL.", LogLevel.WARNING)
    else:
        robo_print("No filename provided", LogLevel.VERBOSE, 4)
        filename = "download"
    facts["download_filename"] = filename
    facts["is_from_app_store"] = False

    # If download URL is hosted on GitHub or SourceForge, we can gather more
    # information.
    if "github.com" in input_path or "githubusercontent.com" in input_path:
        if "github_repo" not in facts:
            facts = inspect_github_url(input_path, args, facts)
    if "sourceforge.net" in input_path:
        if "sourceforge_id" not in facts:
            facts = inspect_sourceforge_url(input_path, args, facts)
            filename = input_path.rstrip("/download").split("/")[-1]

    # Try to determine the type of file downloaded. (Overwrites any previous
    # download_type, because the download URL is the most reliable source.)
    download_format = ""
    robo_print("Determining download format...", LogLevel.VERBOSE)
    for this_format in all_supported_formats:
        if filename.lower().endswith(this_format):
            download_format = this_format
            break  # should stop after the first format match
        if this_format in parsed_url.query:
            download_format = this_format
            break  # should stop after the first format match
    if download_format != "":
        robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)
        facts["download_format"] = download_format
    else:
        robo_print("Unknown download format", LogLevel.VERBOSE, 4)



    # Download the file for continued inspection.
    # TODO(Elliot): Maybe something like this is better for downloading big
    # files? https://gist.github.com/gourneau/1430932
    robo_print("Downloading file for further inspection...", LogLevel.VERBOSE)
    # Remove and recreate the cache folder, so we have a blank slate.
    if os.path.exists(cache_dir):
        shutil.rmtree(cache_dir)
    create_dest_dirs(cache_dir)

    # Write the file to our cache folder.
    try:
        raw_download = urlopen(input_path)
    except Exception as err:
        # Try again, this time with a user-agent.
        try:
            opener = build_opener()
            opener.addheaders = [('User-agent', 'Mozilla/5.0')]
            raw_download = opener.open(input_path)
            robo_print("I had to use a different user-agent in order to "
                       "download this file. If you run the recipes and get a "
                       "\"Can't open URL\" error, it means AutoPkg "
                       "encountered the same problem.", LogLevel.WARNING)
            facts["user-agent"] = "Mozilla/5.0"
        except Exception as err:
            robo_print("Error encountered during file download. "
                       "(%s)" % err, LogLevel.WARNING)
            return facts  # Might still be able to recover from this.
    with open("%s/%s" % (cache_dir, filename), "wb") as download_file:
        download_file.write(raw_download.read())
        robo_print("Downloaded to %s/%s" % (cache_dir, filename), LogLevel.VERBOSE, 4)

    robo_print("Verifying downloaded file format...", LogLevel.VERBOSE)
    # Only proceed if we haven't inspected the app already.
    if "app" in facts["inspections"]:
        return facts

    # Open the disk image (or test to see whether the download is one).
    if download_format == "" or download_format in supported_image_formats:

        # Mount the dmg and look for an app.
        # TODO(Elliot): Handle dmgs with license agreements:
        # https://github.com/autopkg/autopkg/blob/master/Code/autopkglib/DmgMounter.py#L74-L98
        cmd = "/usr/bin/hdiutil attach -plist \"%s/%s\"" % (cache_dir, filename)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was a disk image. Make a note of that.
            if download_format == "":
                download_format = "dmg"  # most common disk image format
                facts["download_format"] = download_format
            robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_image_formats):
                facts["download_filename"] = facts["download_filename"] + ".dmg"

            # Clean the output for cases where the dmg has a license agreement.
            out_clean = out[out.find("<?xml"):]

            # Locate and inspect the app.
            with open("%s/dmg_attach.plist" % cache_dir, "wb") as dmg_plist:
                dmg_plist.write(out_clean)
            try:
                dmg_dict = FoundationPlist.readPlist("%s/dmg_attach.plist" % cache_dir)
            except Exception:
                robo_print("Shoot, I had trouble parsing the output of "
                           "hdiutil while mounting the downloaded dmg. Sorry "
                           "about that.", LogLevel.ERROR)
            dmg_mount = dmg_dict["system-entities"][-1]["mount-point"]
            for this_file in os.listdir(dmg_mount):
                if this_file.endswith(".app"):
                    # Copy app to cache folder.
                    # TODO(Elliot): What if .app isn't on root of dmg mount?
                    attached_app_path = "%s/%s" % (dmg_mount, this_file)
                    cached_app_path = "%s/unpacked/%s" % (cache_dir, this_file)
                    try:
                        shutil.copytree(attached_app_path, cached_app_path)
                    except shutil.Error:
                        pass
                    # Unmount attached volume when done.
                    cmd = "/usr/bin/hdiutil detach \"%s\"" % dmg_mount
                    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
                    facts = inspect_app(cached_app_path, args, facts)
                    break
                if this_file.endswith(".pkg"):
                    # TODO(Elliot): Process the pkg inside the dmg.
                    robo_print("Sorry, I don't yet know how to handle a pkg "
                               "inside a dmg. Hopefully I'll learn "
                               "soon.", LogLevel.ERROR)

    # Open the zip archive (or test to see whether the download is one).
    if download_format == "" or download_format in supported_archive_formats:
        # Unzip the zip and look for an app.
        cmd = "/usr/bin/unzip \"%s/%s\" -d \"%s/unpacked\"" % (cache_dir, filename, cache_dir)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was an archive. Make a note of that.
            if download_format == "":
                download_format = "zip"  # most common archive format
                facts["download_format"] = download_format
            robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_archive_formats):
                facts["download_filename"] = facts["download_filename"] + ".zip"

            # Locate and inspect the app.
            for this_file in os.listdir("%s/unpacked" % cache_dir):
                if this_file.endswith(".app"):
                    # TODO(Elliot): What if .app isn't on root of zip?
                    # Example: https://github.com/jbtule/cdto/releases/download/2_6_0/cdto_2_6.zip
                    cached_app_path = "%s/unpacked/%s" % (cache_dir, this_file)
                    facts = inspect_app(cached_app_path, args, facts)
                    break
                if this_file.endswith(".pkg"):
                    # TODO(Elliot): Process the pkg inside the zip.
                    robo_print("Sorry, I don't yet know how to handle a pkg "
                               "inside a zip. Hopefully I'll learn "
                               "soon.", LogLevel.ERROR)

    # Open the tar archive (or test to see whether the download is one).
    if download_format == "" or download_format in supported_archive_formats:
        # Unzip the tgz and look for an app.
        cmd = "/usr/bin/tar -zxvf \"%s/%s\" -C \"%s/unpacked\"" % (cache_dir, filename, cache_dir)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:

            # Confirmed; the download was an archive. Make a note of that.
            if download_format == "":
                download_format = "tgz"
                facts["download_format"] = download_format
            robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)

            # If the download filename was ambiguous, change it.
            if not facts["download_filename"].endswith(supported_archive_formats):
                facts["download_filename"] = facts["download_filename"] + ".tgz"

            # Locate and inspect the app.
            for this_file in os.listdir("%s/unpacked" % cache_dir):
                if this_file.endswith(".app"):
                    # TODO(Elliot): What if .app isn't on root of tgz?
                    cached_app_path = "%s/unpacked/%s" % (cache_dir, this_file)
                    facts = inspect_app(cached_app_path, args, facts)
                    break
                if this_file.endswith(".pkg"):
                    # TODO(Elliot): Process the pkg inside the tgz.
                    robo_print("Sorry, I don't yet know how to handle a pkg "
                               "inside a tgz. Hopefully I'll learn "
                               "soon.", LogLevel.ERROR)

    # Inspect the installer (or test to see whether the download is one).
    if download_format in supported_install_formats:

        # TODO(Elliot): Use pkgutil to extract contents and look for an app.

        robo_print("Download format is %s" % download_format, LogLevel.VERBOSE, 4)


    if download_format == "":
        robo_print("I've investigated pretty thoroughly, and I'm still not "
                   "sure what the download format is. This could cause "
                   "problems later.", LogLevel.WARNING)

    return facts


def inspect_app(input_path, args, facts):
    """Process an app, gathering required information to create a recipe.
    """

    # Only proceed if we haven't inspected this app yet.
    if "app" in facts["inspections"]:
        return facts
    else:
        facts["inspections"].append("app")

    # Save the path of the app. (Used when overriding AppStoreApp recipes.)
    facts["app_path"] = input_path

    # Read the app's Info.plist.
    robo_print("Validating app...", LogLevel.VERBOSE)
    try:
        info_plist = FoundationPlist.readPlist(input_path + "/Contents/Info.plist")
        robo_print("App seems valid", LogLevel.VERBOSE, 4)
    except Exception:
        robo_print("%s doesn't look like a valid app to me." % input_path, LogLevel.ERROR)

    # Get the filename of the app (which is usually the same as the app name.)
    app_file = os.path.basename(input_path)[:-4]

    # Determine the name of the app. (Overwrites any previous app_name, because
    # the app Info.plist itself is the most reliable source.)
    app_name = ""
    robo_print("Getting app name...", LogLevel.VERBOSE)
    if "CFBundleName" in info_plist:
        app_name = info_plist["CFBundleName"]
    elif "CFBundleExecutable" in info_plist:
        app_name = info_plist["CFBundleExecutable"]
    else:
        app_name = app_file
    robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
    facts["app_name"] = app_name

    # If the app's filename is different than the app's name, we need to make
    # a note of that. Many recipes require another input variable for this.
    if app_name != app_file:
        robo_print("App name differs from the actual app filename.", LogLevel.VERBOSE)
        robo_print("Actual app filename: %s.app" % app_file, LogLevel.VERBOSE, 4)
        facts["app_file"] = app_file

    # Determine the bundle identifier of the app.
    if "bundle_id" not in facts:
        bundle_id = ""
        robo_print("Getting bundle identifier...", LogLevel.VERBOSE)
        if "CFBundleIdentifier" in info_plist:
            bundle_id = info_plist["CFBundleIdentifier"]
        else:
            robo_print("This app doesn't have a bundle identifier.", LogLevel.WARNING)
        if bundle_id != "":
            robo_print("Bundle idenfitier is: %s" % bundle_id, LogLevel.VERBOSE, 4)
            facts["bundle_id"] = bundle_id

    # Attempt to determine how to download this app.
    if "sparkle_feed" not in facts:
        sparkle_feed = ""
        download_format = ""
        robo_print("Checking for a Sparkle feed...", LogLevel.VERBOSE)
        if "SUFeedURL" in info_plist:
            sparkle_feed = info_plist["SUFeedURL"]
            facts = inspect_sparkle_feed_url(sparkle_feed, args, facts)
        elif "SUOriginalFeedURL" in info_plist:
            sparkle_feed = info_plist["SUOriginalFeedURL"]
            facts = inspect_sparkle_feed_url(sparkle_feed, args, facts)
        else:
            robo_print("No Sparkle feed", LogLevel.VERBOSE, 4)

    # TODO(Elliot): Are there ways to download other than Sparkle that are
    # exposed in the app's Info.plist?

    if "is_from_app_store" not in facts:
        robo_print("Determining whether app was downloaded from the Mac App "
                   "Store...", LogLevel.VERBOSE)
        if os.path.exists("%s/Contents/_MASReceipt/receipt" % input_path):
            robo_print("App came from the App Store", LogLevel.VERBOSE, 4)
            facts["is_from_app_store"] = True
        else:
            robo_print("App did not come from the App Store", LogLevel.VERBOSE, 4)
            facts["is_from_app_store"] = False

    # Determine whether to use CFBundleShortVersionString or
    # CFBundleVersion for versioning.
    if "version_key" not in facts:
        version_key = ""
        robo_print("Looking for version key...", LogLevel.VERBOSE)
        if "CFBundleShortVersionString" in info_plist:
            if "CFBundleVersion" in info_plist:
                # Both keys exist, so we must decide with a cage match!
                try:
                    if StrictVersion(info_plist["CFBundleShortVersionString"]):
                        # CFBundleShortVersionString is strict. Use it.
                        version_key = "CFBundleShortVersionString"
                except ValueError:
                    # CFBundleShortVersionString is not strict.
                    try:
                        if StrictVersion(info_plist["CFBundleVersion"]):
                            # CFBundleVersion is strict. Use it.
                            version_key = "CFBundleVersion"
                    except ValueError:
                        # Neither are strict versions. Are they integers?
                        if info_plist["CFBundleShortVersionString"].isdigit():
                            version_key = "CFBundleShortVersionString"
                        elif info_plist["CFBundleVersion"].isdigit():
                            version_key = "CFBundleVersion"
                        else:
                            # CFBundleShortVersionString wins by default.
                            version_key = "CFBundleShortVersionString"
            else:
                version_key = "CFBundleShortVersionString"
        else:
            if "CFBundleVersion" in info_plist:
                version_key = "CFBundleVersion"
        if version_key != "":
            robo_print("Version key is: %s (%s)" %
                       (version_key, info_plist[version_key]), LogLevel.VERBOSE, 4)
            facts["version_key"] = version_key
        else:
            robo_print("Sorry, I can't determine which version key to use "
                       "for this app.", LogLevel.ERROR)

    # Determine path to the app's icon.
    if "icon_path" not in facts:
        icon_path = ""
        robo_print("Looking for app icon...", LogLevel.VERBOSE)
        if "CFBundleIconFile" in info_plist:
            icon_path = "%s/Contents/Resources/%s" % (
                input_path, info_plist["CFBundleIconFile"])
        else:
            robo_print("Can't determine app icon.", LogLevel.WARNING)
        if icon_path != "":
            robo_print("App icon is: %s" % icon_path, LogLevel.VERBOSE, 4)
            facts["icon_path"] = icon_path

    # Attempt to get a description of the app from MacUpdate.com.
    if "description" not in facts:
        robo_print("Getting app description from MacUpdate...", LogLevel.VERBOSE)
        description = get_app_description(app_name)
        if description != "":
            robo_print("Description: %s" % description, LogLevel.VERBOSE, 4)
            facts["description"] = description

    # Attempt to determine code signing verification/requirements.
    if "codesign_status" not in facts:
        codesign_status = ""
        codesign_reqs = ""
        robo_print("Determining whether app is codesigned...", LogLevel.VERBOSE)
        cmd = "codesign --display -r- \"%s\"" % (input_path)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:
            codesign_status = "signed"
            # Determine code signing requirements.
            marker = "designated => "
            for line in out.split("\n"):
                if line.startswith(marker):
                    codesign_reqs = line[len(marker):]
        else:
            codesign_status = "unsigned"
        robo_print("Codesign status is: %s" % codesign_status, LogLevel.VERBOSE, 4)
        facts["codesign_status"] = codesign_status
        if codesign_reqs != "":
            robo_print("Codesign requirements are: %s" % codesign_reqs, LogLevel.VERBOSE, 4)
            facts["codesign_reqs"] = codesign_reqs

    # Attempt to determine name of developer and code signature version.
    if "developer" not in facts and codesign_status != "unsigned":
        developer = ""
        codesign_version = ""
        robo_print("Determining application developer and codesign version...", LogLevel.VERBOSE)
        cmd = "codesign --display -r- --verbose=3 \"%s\"" % (input_path)
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        if exitcode == 0:
            dev_marker = "Authority=Developer ID Application: "
            vers_marker = "Sealed Resources version="
            # For some reason, the information we want is output to stderr.
            for line in err.split("\n"):
                if line.startswith(dev_marker):
                    if " (" in line:
                        line = line.split(" (")[0]
                    developer = line[len(dev_marker):]
                if line.startswith(vers_marker):
                    codesign_version = line[len(vers_marker):len(vers_marker) + 1]
        if developer != "":
            robo_print("Developer: %s" % developer, LogLevel.VERBOSE, 4)
            facts["developer"] = developer
        if codesign_version != "":
            robo_print("Codesign version: %s" % codesign_version, LogLevel.VERBOSE, 4)
            if codesign_version == "1":
                robo_print("This app uses an obsolete code signature.", LogLevel.WARNING)
                facts["codesign_status"] = "obsolete"

    return facts


def inspect_recipe(input_path, args, facts):
    """Process a recipe, gathering information useful for building other types
    of recipes.
    """

    # Read the recipe as a plist.
    robo_print("Validating recipe...", LogLevel.VERBOSE)
    try:
        input_recipe = FoundationPlist.readPlist(input_path)
        robo_print("Recipe is a valid plist", LogLevel.VERBOSE, 4)
    except Exception:
        robo_print("Could not parse recipe as a plist.", LogLevel.WARNING)

    # Run autopkg info on the recipe and save the output.
    cmd = "autopkg info \"%s\"" % input_path
    exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    if exitcode == 0:
        out = out.split("\n")
    else:
        robo_print("Could not run \"autopkg info\" on recipe.", LogLevel.WARNING)

    # Determine the name of the app.
    if "app_name" not in facts:
        app_name = ""
        robo_print("Getting name of app...", LogLevel.VERBOSE)
        if "Input" in input_recipe:
            if "NAME" in input_recipe["Input"]:
                app_name = input_recipe["Input"]["NAME"]
        if app_name != "":
            robo_print("App name is: %s" % app_name, LogLevel.VERBOSE, 4)
            facts["app_name"] = app_name
            # If the app exists on disk, we can cheat by using it as input.
            if os.path.exists("/Applications/%s.app" % app_name):
                inspect_app("/Applications/%s.app" % app_name, args, facts)

    # Determine parent recipe, and get more facts from it.
    marker = "Parent recipe(s):"
    parent_recipe_path = ""
    robo_print("Looking for a parent recipe...", LogLevel.VERBOSE)
    for line in out:
        if marker in line:
            parent_recipe_path = line[len(marker):].lstrip()
    if parent_recipe_path != "":
        robo_print("Parent recipe is: %s" % parent_recipe_path, LogLevel.VERBOSE, 4)
        facts = inspect_recipe(parent_recipe_path, args, facts)
    else:
        robo_print("No parent recipe found", LogLevel.VERBOSE, 4)

    # Determine whether there's a Sparkle feed.
    if "sparkle_feed" not in facts:
        marker = "SPARKLE"
        robo_print("Looking for a Sparkle feed...", LogLevel.VERBOSE)
        for line in out:
            if marker in line:
                sparkle_feed = line.split("\"")[-2]
                facts = inspect_sparkle_feed_url(sparkle_feed, args, facts)

    # Determine whether there's a download URL.
    if "download_url" not in facts:
        marker = "DOWNLOAD_URL"
        robo_print("Looking for a direct download URL...", LogLevel.VERBOSE)
        for line in out:
            if marker in line:
                download_url = line[len(marker):].lstrip()
                facts = inspect_download_url(download_url, args, facts)

    # Get the download file format.
    if "download_format" not in facts:
        download_format = ""
        robo_print("Trying to determine download format...", LogLevel.VERBOSE)
        for test_format in all_supported_formats:
            cmd = "grep '.%s</string>' '%s'" % (test_format, input_path)
            exitcode, out, err = get_exitcode_stdout_stderr(cmd)
            if exitcode == 0:
                download_format = test_format
                break
        if download_format != "":
            robo_print("Download format (from recipe) is: %s" % download_format, LogLevel.VERBOSE, 4)
            facts["download_format"] = download_format

    # Run the recipe and inspect the resulting app.
    # robo_print("Running recipe to see what we get...", LogLevel.VERBOSE)
    # cmd = "autopkg run \"%s\"" % input_path
    # exitcode, out, err = get_exitcode_stdout_stderr(cmd)
    # if exitcode == 0:
    #     pass

    return facts


def create_existing_recipe_list(app_name, recipes, args):
    """Use autopkg search results to build existing recipe list.

    Args:
        app_name: The name of the app for which we're searching for recipes.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.
    """

    # TODO(Elliot): Suggest users create GitHub API token to prevent limiting.

    # If --include-existing is specified, no need to search at all.
    if args.include_existing is True:
        return

    recipe_searches = []
    recipe_searches.append(app_name)

    app_name_no_space = "".join(app_name.split())
    if app_name_no_space != app_name:
        recipe_searches.append(app_name_no_space)

    app_name_no_symbol = re.sub(r'[^\w]', '', app_name)
    if app_name_no_symbol != app_name and app_name_no_symbol != app_name_no_space:
        recipe_searches.append(app_name_no_symbol)

    for this_search in recipe_searches:
        robo_print("Searching for existing AutoPkg recipes for \"%s\"..." % this_search, LogLevel.VERBOSE)
        cmd = "/usr/local/bin/autopkg search -p \"%s\"" % this_search
        exitcode, out, err = get_exitcode_stdout_stderr(cmd)
        out = out.split("\n")
        if exitcode == 0:
            # TODO(Elliot): There's probably a more efficient way to do this.
            # For each recipe type, see if it exists in the search results.
            is_existing = False
            for recipe in recipes:
                recipe_name = "%s.%s.recipe" % (this_search, recipe["type"])
                for line in out:
                    if line.lower().startswith(recipe_name.lower()):
                        # Set to False by default. If found, set to True.
                        recipe["existing"] = True
                        robo_print("Found existing %s" % recipe_name, LogLevel.VERBOSE, 4)
                        is_existing = True
                        break
            if not is_existing:
                robo_print("No results", LogLevel.VERBOSE, 4)
        else:
            robo_print(err, LogLevel.ERROR)


def create_buildable_recipe_list(app_name, recipes, args, facts):
    """Add any preferred recipe types that don't already exist to the buildable
    list.

    Args:
        app_name: The name of the app for which we're searching for recipes.
        recipes: The list of known recipe types, created by init_recipes().
        args: The command line arguments.
        facts: A continually-updated dictionary containing all the information
            we know so far about the app associated with the input path.
    """

    # Determine which recipes are buildable based on "preferred" preference
    # values and the --include-existing argument.
    for recipe in recipes:
        if args.include_existing is False:
            if recipe["preferred"] is True and recipe["existing"] is False:
                recipe["buildable"] = True
        else:
            if recipe["preferred"] is True:
                recipe["buildable"] = True

    # TODO(Elliot):  Do we also need to consider which facts we have collected
    # at this point? For example, if we didn't find a Sparkle URL or any other
    # way to download the app, it's unlikely that we can produce a download
    # recipe.


def debug_dump(items):
    """Dump all the variables we know about to output.

    Args:
        items: A dict of dicts of all the things to dump to output.
    """
    for key, value in items.iteritems():
        print "%s\n%s:\n\n%s\n%s" % (BColors.DEBUG, key.upper(),
                                     pprint.pformat(value), BColors.ENDC)


def congratulate(prefs):
    """Display a friendly congratulatory message upon creating recipes.

    Args:
        prefs: A dictionary containing a key/value pair for each preference.
    """
    congrats_msg = (
        "Amazing.",
        "Easy peasy.",
        "Fantastic.",
        "Good on ya!",
        "Imagine all the typing you saved.",
        "Isn't meta-automation great?",
        "(Yep, it's pretty fun for me too.)",
        "Pretty cool, right?",
        "Round of applause for you!",
        "Terrific job!",
        "Thanks!",
        "That's awesome!",
        "Want to do another?",
        "Well done!",
        "You rock star, you."
    )
    if prefs["RecipeCreateCount"] == 1:
        robo_print("\nYou've created your first recipe with Recipe "
                   "Robot. Congratulations!\n")
    elif prefs["RecipeCreateCount"] > 1:
        robo_print("\nYou've now created %s recipes with Recipe Robot. "
                   "%s\n" % (prefs["RecipeCreateCount"],
                             random.choice(congrats_msg)))


# TODO(Elliot): Make main() shorter. Just a flowchart for the logic.
def main():
    """Make the magic happen."""

    try:
        recipe_robot_lib.tools.reset_term_colors()
        print_welcome_text()

        argparser = build_argument_parser()
        args = argparser.parse_args()
        if args.include_existing is True:
            robo_print("Will build recipes even if they already exist in "
                       "\"autopkg search\" results. Please don't upload "
                       "duplicate recipes.", LogLevel.WARNING)
        if args.verbose is True or OutputMode.verbose_mode is True:
            OutputMode.set_verbose_mode(True)

        # Create the master recipe information list.
        recipes = init_recipes()

        # Read or create the user preferences.
        prefs = {}
        prefs = init_prefs(prefs, recipes, args)

        input_path = args.input_path
        input_path = input_path.rstrip("/ ")
        robo_print("Processing %s ..." % input_path)

        # Collect facts from the input path, based on the type of path given.
        facts = {}
        process_input_path(input_path, args, facts)

        # Look up existing recipes.
        create_existing_recipe_list(facts["app_name"], recipes, args)

        # Determine which recipes we can build.
        create_buildable_recipe_list(facts["app_name"], recipes, args, facts)

        # Create recipes for the recipe types that were selected above.
        recipe_robot_lib.generate_recipes(facts, prefs, recipes)

        # If debug is on, print all the things.
        if OutputMode.debug_mode is True:
            debug_dump({
                "Command line arguments": args,
                "Supported file formats": all_supported_formats,
                "Preferences for this session": prefs,
                "Recipe information": recipes,
                "Facts we have collected": facts
            })

        # Pat on the back!
        congratulate(prefs)

        # Clean up cache folder.
        if os.path.exists(cache_dir):
            shutil.rmtree(cache_dir)

    # If killed, make sure to reset the terminal color with our dying breath.
    except (KeyboardInterrupt, SystemExit):
        recipe_robot_lib.tools.reset_term_colors()


if __name__ == '__main__':
    main()
